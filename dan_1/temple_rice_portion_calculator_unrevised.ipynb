{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ruliana/pytorch-katas/blob/main/dan_1/temple_rice_portion_calculator_unrevised.ipynb)\n",
    "\n",
    "üèÆ The Ancient Scroll Unfurls üèÆ\n",
    "\n",
    "THE SACRED RICE PORTION PROPHECY\n",
    "Dan Level: 1 (Temple Sweeper) | Time: 75 minutes | Sacred Arts: Multi-Feature Tensors, Optimizer Wisdom, Data Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìú THE MASTER'S CHALLENGE\n",
    "\n",
    "Young Grasshopper, another sacred duty awaits you in the temple's heart.\n",
    "\n",
    "The temple's rice stores have been a source of great confusion. Each day, Cook Oh-Pai-Timizer\n",
    "must calculate the perfect amount of rice to prepare for the monks' meals. Too little,\n",
    "and the disciples go hungry during their long meditation sessions. Too much, and precious\n",
    "grains are wasted - a violation of the temple's principles of mindful consumption.\n",
    "\n",
    "The rice requirements depend on mysterious factors: the number of monks present, the type\n",
    "of meal being served, and even the season of the year affects appetites!\n",
    "\n",
    "*CLANG! SPLASH!*\n",
    "\n",
    "\"Oh no! Forgive me!\" cries He-Ao-World from the kitchen storage, where rice measurement\n",
    "scrolls now float in a puddle of spilled water. \"I was organizing the portion records\n",
    "and... well, now some of the measurements have run together! The numbers for winter\n",
    "feasts are mixed with summer breakfasts, and I can't tell which monks were counted\n",
    "twice!\"\n",
    "\n",
    "\"Rice,\" muses Master Pai-Torch, appearing silently in the doorway, \"is not governed by\n",
    "a single truth, but by the harmony of many factors. The wise cook learns to weigh\n",
    "multiple ingredients in the recipe of prediction.\"\n",
    "\n",
    "Your sacred duty: Create a model that can predict the perfect rice portions based on\n",
    "multiple temple variables.\n",
    "\n",
    "üéØ THE SACRED OBJECTIVES\n",
    "\n",
    "- [ ] Master multi-feature tensor creation and manipulation\n",
    "- [ ] Forge a Linear Wisdom layer that handles multiple inputs\n",
    "- [ ] Learn the ancient art of data scaling and preprocessing\n",
    "- [ ] Compare different optimization spirits (SGD vs Adam)\n",
    "- [ ] Practice the sacred ritual of train/test splitting\n",
    "- [ ] Measure your model's wisdom with evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üçö THE SACRED IMPORTS\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from typing import Tuple, Dict\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure reproducible mystical results\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üçö THE SACRED RICE DATA GENERATION SCROLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_temple_rice_data(n_meals: int = 200, kitchen_chaos: float = 0.1,\n",
    "                            sacred_seed: int = 42) -> Tuple[torch.Tensor, torch.Tensor, list]:\n",
    "    \"\"\"\n",
    "    Generate observations of temple rice consumption patterns.\n",
    "    \n",
    "    Ancient wisdom suggests rice needed follows this sacred formula:\n",
    "    rice_cups = 0.8 * n_monks + 1.2 * meal_type + 0.3 * season_factor + 2.0\n",
    "    \n",
    "    Args:\n",
    "        n_meals: Number of meal observations to simulate\n",
    "        kitchen_chaos: Amount of measurement unpredictability\n",
    "        sacred_seed: Ensures consistent randomness\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (features, rice_amounts, feature_names)\n",
    "    \"\"\"\n",
    "    torch.manual_seed(sacred_seed)\n",
    "    np.random.seed(sacred_seed)\n",
    "    \n",
    "    # Generate temple meal features\n",
    "    n_monks = np.random.randint(5, 30, n_meals)  # 5-30 monks per meal\n",
    "    \n",
    "    # Meal types: 0=breakfast, 1=lunch, 2=dinner (dinner requires more rice)\n",
    "    meal_type = np.random.randint(0, 3, n_meals)\n",
    "    \n",
    "    # Season factors: 0=spring, 1=summer, 2=autumn, 3=winter (winter=more appetite)\n",
    "    season = np.random.randint(0, 4, n_meals)\n",
    "    \n",
    "    # The sacred rice calculation formula\n",
    "    base_rice = 2.0\n",
    "    monk_factor = 0.8\n",
    "    meal_factor = 1.2\n",
    "    season_factor = 0.3\n",
    "    \n",
    "    rice_needed = (monk_factor * n_monks + \n",
    "                  meal_factor * meal_type + \n",
    "                  season_factor * season + \n",
    "                  base_rice)\n",
    "    \n",
    "    # Add kitchen chaos (measurement errors, varying appetites)\n",
    "    chaos = np.random.normal(0, kitchen_chaos * np.std(rice_needed), n_meals)\n",
    "    rice_needed = rice_needed + chaos\n",
    "    \n",
    "    # Even mystical rice has practical limits\n",
    "    rice_needed = np.clip(rice_needed, 1.0, 50.0)\n",
    "    \n",
    "    # Combine features into tensor\n",
    "    features = np.column_stack([n_monks, meal_type, season])\n",
    "    features_tensor = torch.FloatTensor(features)\n",
    "    rice_tensor = torch.FloatTensor(rice_needed).unsqueeze(1)\n",
    "    \n",
    "    feature_names = ['n_monks', 'meal_type', 'season']\n",
    "    \n",
    "    return features_tensor, rice_tensor, feature_names\n",
    "\n",
    "def visualize_rice_wisdom(features: torch.Tensor, rice_amounts: torch.Tensor,\n",
    "                        feature_names: list, predictions: torch.Tensor = None):\n",
    "    \"\"\"Display the sacred patterns of rice consumption.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot each feature vs rice amount\n",
    "    for i, (ax, feature_name) in enumerate(zip(axes.flat[:3], feature_names)):\n",
    "        ax.scatter(features[:, i].numpy(), rice_amounts.numpy(), \n",
    "                  alpha=0.6, color='brown', s=40)\n",
    "        ax.set_xlabel(feature_name.replace('_', ' ').title())\n",
    "        ax.set_ylabel('Rice Cups Needed')\n",
    "        ax.set_title(f'üçö Rice vs {feature_name.replace(\"_\", \" \").title()}')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Predictions vs actual in the 4th subplot\n",
    "    if predictions is not None:\n",
    "        ax = axes.flat[3]\n",
    "        ax.scatter(rice_amounts.numpy(), predictions.detach().numpy(), \n",
    "                  alpha=0.6, color='gold', s=40)\n",
    "        # Perfect prediction line\n",
    "        min_val = min(rice_amounts.min(), predictions.min())\n",
    "        max_val = max(rice_amounts.max(), predictions.max())\n",
    "        ax.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)\n",
    "        ax.set_xlabel('Actual Rice Cups')\n",
    "        ax.set_ylabel('Predicted Rice Cups')\n",
    "        ax.set_title('üéØ Predictions vs Reality')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate the sacred data\n",
    "features, rice_amounts, feature_names = generate_temple_rice_data()\n",
    "print(f\"Generated {len(features)} sacred meal observations\")\n",
    "print(f\"Features: {feature_names}\")\n",
    "print(f\"Feature shapes: {features.shape}\")\n",
    "print(f\"Rice amounts shape: {rice_amounts.shape}\")\n",
    "print(f\"Rice range: {rice_amounts.min():.2f} to {rice_amounts.max():.2f} cups\")\n",
    "\n",
    "# Visualize the sacred patterns\n",
    "visualize_rice_wisdom(features, rice_amounts, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üßÆ THE SACRED ART OF DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sacred_data(features: torch.Tensor, rice_amounts: torch.Tensor, \n",
    "                      test_size: float = 0.2) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Prepare the data for training by scaling and splitting.\n",
    "    \n",
    "    Args:\n",
    "        features: Input features tensor\n",
    "        rice_amounts: Target rice amounts tensor\n",
    "        test_size: Fraction of data to use for testing\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (X_train, X_test, y_train, y_test)\n",
    "    \"\"\"\n",
    "    # TODO: Convert tensors to numpy for sklearn compatibility\n",
    "    X_np = None\n",
    "    y_np = None\n",
    "    \n",
    "    # TODO: Split the data into training and testing sets\n",
    "    # Hint: Use train_test_split with random_state=42 for reproducibility\n",
    "    X_train_np, X_test_np, y_train_np, y_test_np = None, None, None, None\n",
    "    \n",
    "    # TODO: Scale the features using StandardScaler\n",
    "    # Hint: Fit the scaler on training data only, then transform both sets\n",
    "    scaler = None\n",
    "    X_train_scaled = None\n",
    "    X_test_scaled = None\n",
    "    \n",
    "    # Convert back to tensors\n",
    "    X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "    X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "    y_train_tensor = torch.FloatTensor(y_train_np).unsqueeze(1)\n",
    "    y_test_tensor = torch.FloatTensor(y_test_np).unsqueeze(1)\n",
    "    \n",
    "    print(f\"Training set size: {len(X_train_tensor)}\")\n",
    "    print(f\"Testing set size: {len(X_test_tensor)}\")\n",
    "    \n",
    "    return X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor\n",
    "\n",
    "# Prepare the sacred data\n",
    "# X_train, X_test, y_train, y_test = prepare_sacred_data(features, rice_amounts)\n",
    "print(\"üìä Data preparation wisdom awaits your implementation...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÆ THE RICE PORTION PREDICTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RicePortionPredictor(nn.Module):\n",
    "    \"\"\"A mystical artifact for understanding sacred rice consumption patterns.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_features: int = 3):\n",
    "        super(RicePortionPredictor, self).__init__()\n",
    "        # TODO: Create the Linear Wisdom layer for multi-feature input\n",
    "        # Hint: input_features should be 3 (n_monks, meal_type, season)\n",
    "        # Output should be 1 (rice cups needed)\n",
    "        self.linear_wisdom = None\n",
    "    \n",
    "    def divine_rice_portions(self, temple_features: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Channel your understanding through the mystical network.\"\"\"\n",
    "        # TODO: Pass the multi-feature input through your Linear Wisdom\n",
    "        # Remember: the network must handle multiple inputs simultaneously\n",
    "        return None\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"The sacred forward pass - this is called automatically by PyTorch.\"\"\"\n",
    "        return self.divine_rice_portions(x)\n",
    "\n",
    "# Create your mystical predictor\n",
    "rice_predictor = RicePortionPredictor()\n",
    "print(\"üçö Your Rice Portion Predictor has been forged!\")\n",
    "print(f\"Sacred parameters: {sum(p.numel() for p in rice_predictor.parameters())}\")\n",
    "print(f\"Model architecture: {rice_predictor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚öîÔ∏è THE DUAL OPTIMIZER TRAINING RITUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rice_predictor(model: nn.Module, X_train: torch.Tensor, y_train: torch.Tensor,\n",
    "                       X_test: torch.Tensor, y_test: torch.Tensor,\n",
    "                       optimizer_name: str = 'sgd', epochs: int = 1000, \n",
    "                       learning_rate: float = 0.01) -> Dict[str, list]:\n",
    "    \"\"\"\n",
    "    Train the rice portion prediction model.\n",
    "    \n",
    "    Args:\n",
    "        optimizer_name: 'sgd' or 'adam' - choose your optimization spirit\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing training history\n",
    "    \"\"\"\n",
    "    # TODO: Choose your loss calculation method\n",
    "    # Hint: Mean Squared Error works well for regression\n",
    "    criterion = None\n",
    "    \n",
    "    # TODO: Choose your optimization spirit\n",
    "    # Hint: Compare SGD vs Adam - they have different strengths\n",
    "    if optimizer_name.lower() == 'sgd':\n",
    "        optimizer = None\n",
    "    elif optimizer_name.lower() == 'adam':\n",
    "        optimizer = None\n",
    "    else:\n",
    "        raise ValueError(\"Choose 'sgd' or 'adam' as your optimization spirit\")\n",
    "    \n",
    "    history = {'train_loss': [], 'test_loss': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        \n",
    "        # TODO: CRITICAL - Clear the gradient spirits from previous cycle\n",
    "        \n",
    "        # TODO: Forward pass - get predictions\n",
    "        train_predictions = None\n",
    "        \n",
    "        # TODO: Compute the training loss\n",
    "        train_loss = None\n",
    "        \n",
    "        # TODO: Backward pass - compute gradients\n",
    "        \n",
    "        # TODO: Update parameters\n",
    "        \n",
    "        # Evaluation phase (no gradient computation needed)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_predictions = model(X_test)\n",
    "            test_loss = criterion(test_predictions, y_test)\n",
    "        \n",
    "        history['train_loss'].append(train_loss.item())\n",
    "        history['test_loss'].append(test_loss.item())\n",
    "        \n",
    "        # Report progress to the masters\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}] | '\n",
    "                  f'Train Loss: {train_loss.item():.4f} | '\n",
    "                  f'Test Loss: {test_loss.item():.4f}')\n",
    "            \n",
    "            if train_loss.item() < 5.0:\n",
    "                print(f\"üçö Cook Oh-Pai-Timizer approves - the {optimizer_name.upper()} spirits are working!\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Prepare for the dual training ritual\n",
    "print(\"üßò The Dual Optimizer Training Ritual awaits...\")\n",
    "print(\"Master Pai-Torch whispers: 'Each optimization spirit has its own wisdom to offer.'\")\n",
    "\n",
    "# Training begins here - uncomment after implementing the TODOs\n",
    "# sgd_history = train_rice_predictor(rice_predictor, X_train, y_train, X_test, y_test, \n",
    "#                                   optimizer_name='sgd', learning_rate=0.01)\n",
    "\n",
    "# Create a fresh model for Adam training\n",
    "# rice_predictor_adam = RicePortionPredictor()\n",
    "# adam_history = train_rice_predictor(rice_predictor_adam, X_train, y_train, X_test, y_test,\n",
    "#                                    optimizer_name='adam', learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìä VISUALIZATION OF THE SACRED TRAINING COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_optimization_spirits(sgd_history: Dict, adam_history: Dict):\n",
    "    \"\"\"Compare the wisdom of different optimization spirits.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Training loss comparison\n",
    "    axes[0, 0].plot(sgd_history['train_loss'], label='SGD', color='blue', linewidth=2)\n",
    "    axes[0, 0].plot(adam_history['train_loss'], label='Adam', color='red', linewidth=2)\n",
    "    axes[0, 0].set_title('üèÉ Training Loss: The Race of Optimizers')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Training Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Test loss comparison\n",
    "    axes[0, 1].plot(sgd_history['test_loss'], label='SGD', color='blue', linewidth=2)\n",
    "    axes[0, 1].plot(adam_history['test_loss'], label='Adam', color='red', linewidth=2)\n",
    "    axes[0, 1].set_title('üéØ Test Loss: The True Wisdom Test')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Test Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Final comparison summary\n",
    "    optimizers = ['SGD', 'Adam']\n",
    "    final_train_losses = [sgd_history['train_loss'][-1], adam_history['train_loss'][-1]]\n",
    "    final_test_losses = [sgd_history['test_loss'][-1], adam_history['test_loss'][-1]]\n",
    "    \n",
    "    x_pos = np.arange(len(optimizers))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[1, 0].bar(x_pos - width/2, final_train_losses, width, label='Train Loss', color='lightblue')\n",
    "    axes[1, 0].bar(x_pos + width/2, final_test_losses, width, label='Test Loss', color='lightcoral')\n",
    "    axes[1, 0].set_title('‚ö° Final Battle: Which Spirit Wins?')\n",
    "    axes[1, 0].set_xlabel('Optimization Spirit')\n",
    "    axes[1, 0].set_ylabel('Final Loss')\n",
    "    axes[1, 0].set_xticks(x_pos)\n",
    "    axes[1, 0].set_xticklabels(optimizers)\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Remove empty subplot\n",
    "    axes[1, 1].remove()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Uncomment after training is complete\n",
    "# compare_optimization_spirits(sgd_history, adam_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö° THE TRIALS OF MASTERY\n",
    "\n",
    "## Trial 1: Multi-Feature Mastery\n",
    "- [ ] Model accepts 3-feature input and produces 1-feature output\n",
    "- [ ] Training loss decreases consistently for both optimizers\n",
    "- [ ] Test loss remains close to training loss (no severe overfitting)\n",
    "- [ ] Final test loss below 5.0 for at least one optimizer\n",
    "\n",
    "## Trial 2: Optimizer Wisdom Comparison\n",
    "- [ ] Both SGD and Adam successfully train the model\n",
    "- [ ] You can explain which optimizer performed better and why\n",
    "- [ ] Model parameters reflect reasonable rice portion relationships\n",
    "\n",
    "## Trial 3: Understanding Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_your_rice_wisdom(model, X_test, y_test):\n",
    "    \"\"\"Master Pai-Torch's comprehensive evaluation of your understanding.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Test shape compatibility\n",
    "    test_features = torch.FloatTensor([[15, 2, 1]])  # 15 monks, dinner, summer\n",
    "    prediction = model(test_features)\n",
    "    assert prediction.shape == (1, 1), \"The rice prediction shapes must align!\"\n",
    "    \n",
    "    # Test on full test set\n",
    "    with torch.no_grad():\n",
    "        test_predictions = model(X_test)\n",
    "        test_mse = mean_squared_error(y_test.numpy(), test_predictions.numpy())\n",
    "        test_r2 = r2_score(y_test.numpy(), test_predictions.numpy())\n",
    "    \n",
    "    print(f\"Test MSE: {test_mse:.4f}\")\n",
    "    print(f\"Test R¬≤: {test_r2:.4f}\")\n",
    "    \n",
    "    # Check if model learned reasonable relationships\n",
    "    params = list(model.parameters())\n",
    "    weights = params[0].data.numpy().flatten()\n",
    "    bias = params[1].data.numpy().item()\n",
    "    \n",
    "    print(f\"\\nLearned weights: {weights}\")\n",
    "    print(f\"Learned bias: {bias:.3f}\")\n",
    "    \n",
    "    # The first weight should be positive (more monks = more rice)\n",
    "    assert weights[0] > 0, \"More monks should need more rice!\"\n",
    "    \n",
    "    # Test should achieve reasonable accuracy\n",
    "    assert test_r2 > 0.8, f\"R¬≤ of {test_r2:.3f} suggests the model needs more training!\"\n",
    "    \n",
    "    print(\"\\nüéâ Cook Oh-Pai-Timizer beams with pride - your rice wisdom is profound!\")\n",
    "    \n",
    "    return test_mse, test_r2\n",
    "\n",
    "# Test your wisdom after training\n",
    "# test_mse, test_r2 = test_your_rice_wisdom(rice_predictor, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üå∏ THE FOUR PATHS OF MASTERY: PROGRESSIVE EXTENSIONS\n",
    "\n",
    "## Extension 1: Master Ao-Tougrad's Feature Engineering\n",
    "*\"The wise predictor creates new features from existing wisdom.\"*\n",
    "\n",
    "*A shadow falls across your work as Master Ao-Tougrad appears*\n",
    "\n",
    "\"Young grasshopper, your multi-feature mastery grows strong. But consider this:\n",
    "what happens when monks arrive together in groups? When winter dinners combine\n",
    "the appetite of cold weather with the heartiness of evening meals? Sometimes\n",
    "the true wisdom lies not in more features, but in the interaction between them.\"\n",
    "\n",
    "**NEW CONCEPTS**: Feature engineering, interaction terms, polynomial features  \n",
    "**DIFFICULTY**: +15% (still Dan 1, but smarter features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interaction_features(features: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Create interaction features to capture complex relationships.\n",
    "    \n",
    "    Args:\n",
    "        features: Original features [n_monks, meal_type, season]\n",
    "    \n",
    "    Returns:\n",
    "        Enhanced features with interactions\n",
    "    \"\"\"\n",
    "    # TODO: Add interaction terms\n",
    "    # Hint: monks * meal_type captures \"dinner needs more rice per monk\"\n",
    "    # Hint: monks * season captures \"winter monks eat more\"\n",
    "    # Hint: meal_type * season captures \"winter dinners are largest\"\n",
    "    pass\n",
    "\n",
    "# TRIAL: Train your model with engineered features\n",
    "# SUCCESS: Achieve better R¬≤ score with the same model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension 2: Cook Oh-Pai-Timizer's Batch Cooking Wisdom\n",
    "*\"A master chef prepares many meals simultaneously, not one at a time!\"*\n",
    "\n",
    "*Cook Oh-Pai-Timizer appears with a large pot and ladle*\n",
    "\n",
    "\"Grasshopper, your single-meal predictions serve well for daily planning. But what\n",
    "happens during festival weeks when we must prepare dozens of meals in advance?\n",
    "The temple's efficiency comes from batch processing - predicting rice needs for\n",
    "entire weeks at once!\"\n",
    "\n",
    "**NEW CONCEPTS**: Batch prediction, vectorized operations, efficiency optimization  \n",
    "**DIFFICULTY**: +25% (still Dan 1, but thinking in batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_festival_week_data(n_weeks: int = 5) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generate meal data for entire festival weeks.\n",
    "    Each week has 21 meals (7 days √ó 3 meals/day).\n",
    "    \n",
    "    Returns:\n",
    "        Batch of meal features for multiple weeks\n",
    "    \"\"\"\n",
    "    # TODO: Generate batch data for festival weeks\n",
    "    # Hint: Your existing model should handle this automatically\n",
    "    pass\n",
    "\n",
    "def predict_festival_rice_needs(model, festival_data: torch.Tensor) -> Dict:\n",
    "    \"\"\"\n",
    "    Predict rice needs for entire festival weeks.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with weekly totals and daily breakdowns\n",
    "    \"\"\"\n",
    "    # TODO: Make batch predictions and organize by week\n",
    "    # Hint: Reshape predictions to separate weeks and days\n",
    "    pass\n",
    "\n",
    "# TRIAL: Predict rice needs for multiple festival weeks\n",
    "# SUCCESS: Efficiently process batches of 100+ meals simultaneously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension 3: He-Ao-World's Noisy Data Challenge\n",
    "*\"These old records seem to have some... inconsistencies in them.\"*\n",
    "\n",
    "*He-Ao-World shuffles over with a stack of water-damaged scrolls*\n",
    "\n",
    "\"Oh dear! I'm afraid some of our historical rice records got mixed up in the\n",
    "monsoon season. Some measurements might be in different units, others might\n",
    "have extra digits, and I think a few guest counts include the temple dogs by\n",
    "mistake! Can your model still learn from imperfect data?\"\n",
    "\n",
    "**NEW CONCEPTS**: Robust training, outlier detection, data cleaning  \n",
    "**DIFFICULTY**: +35% (still Dan 1, but messy real-world data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_realistic_noise(features: torch.Tensor, rice_amounts: torch.Tensor, \n",
    "                       noise_level: float = 0.1) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Add realistic data inconsistencies to simulate He-Ao-World's \"accidents\".\n",
    "    \n",
    "    Args:\n",
    "        noise_level: Fraction of data to corrupt\n",
    "    \n",
    "    Returns:\n",
    "        Noisy features and rice amounts\n",
    "    \"\"\"\n",
    "    # TODO: Add various types of realistic noise:\n",
    "    # - Some monk counts doubled (counted twice)\n",
    "    # - Some rice amounts in wrong units\n",
    "    # - A few completely wrong outliers\n",
    "    pass\n",
    "\n",
    "def robust_training_with_outliers(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Train model to be robust against outliers and noise.\n",
    "    \n",
    "    Returns:\n",
    "        Training history with robustness metrics\n",
    "    \"\"\"\n",
    "    # TODO: Implement training strategies that handle noisy data\n",
    "    # Hint: Consider using different loss functions or data cleaning\n",
    "    pass\n",
    "\n",
    "# TRIAL: Train on noisy data and maintain good performance\n",
    "# SUCCESS: Model achieves similar accuracy despite data corruption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension 4: The Temple's Rice Inventory Optimization\n",
    "*\"Prediction is wisdom, but optimization is mastery.\"*\n",
    "\n",
    "*Master Pai-Torch gestures toward the temple's rice storage*\n",
    "\n",
    "\"Young grasshopper, your prediction wisdom has grown deep. But the temple asks\n",
    "a greater question: 'Given our rice storage limits, how should we schedule our\n",
    "meals to minimize waste while ensuring no monk goes hungry?' This is the path\n",
    "from prediction to optimization.\"\n",
    "\n",
    "**NEW CONCEPTS**: Constraint optimization, resource allocation, decision making  \n",
    "**DIFFICULTY**: +45% (still Dan 1, but strategic thinking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_meal_schedule(model, available_rice: float, \n",
    "                         meal_options: torch.Tensor, \n",
    "                         max_meals: int = 10) -> Dict:\n",
    "    \"\"\"\n",
    "    Optimize meal scheduling given rice constraints.\n",
    "    \n",
    "    Args:\n",
    "        available_rice: Total rice cups available\n",
    "        meal_options: Tensor of possible meal configurations\n",
    "        max_meals: Maximum number of meals to schedule\n",
    "    \n",
    "    Returns:\n",
    "        Optimal meal schedule with rice allocation\n",
    "    \"\"\"\n",
    "    # TODO: Use your model to predict rice needs for all meal options\n",
    "    # TODO: Select optimal combination that fits within rice budget\n",
    "    # Hint: This is a combinatorial optimization problem\n",
    "    pass\n",
    "\n",
    "def visualize_rice_optimization(optimal_schedule: Dict, available_rice: float):\n",
    "    \"\"\"\n",
    "    Visualize the optimal meal schedule and rice allocation.\n",
    "    \"\"\"\n",
    "    # TODO: Create visualization showing:\n",
    "    # - Selected meals and their rice requirements\n",
    "    # - Rice budget utilization\n",
    "    # - Comparison with other possible schedules\n",
    "    pass\n",
    "\n",
    "# TRIAL: Optimize meal scheduling for different rice budgets\n",
    "# SUCCESS: Maximize meals served while staying within rice limits\n",
    "# MASTERY: Understand how prediction models enable optimization decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî• CORRECTING YOUR FORM: A SCALING IMBALANCE\n",
    "\n",
    "Cook Oh-Pai-Timizer observes your data preparation with concern. \"Young grasshopper, your ingredient measurements seem... unbalanced. See how some features dominate others like salt overwhelming delicate spices?\"\n",
    "\n",
    "A previous disciple left this flawed data preparation ritual. The model struggles to learn - can you restore proper technique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unbalanced_data_preparation(features, rice_amounts):\n",
    "    \"\"\"This data preparation has lost its balance - your form needs correction! ü•ã\"\"\"\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features.numpy(), rice_amounts.numpy(), test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Convert back to tensors - but something is missing...\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    X_test_tensor = torch.FloatTensor(X_test)\n",
    "    y_train_tensor = torch.FloatTensor(y_train).unsqueeze(1)\n",
    "    y_test_tensor = torch.FloatTensor(y_test).unsqueeze(1)\n",
    "    \n",
    "    return X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor\n",
    "\n",
    "# Cook Oh-Pai-Timizer's guidance: \"What sacred step is missing from this preparation?\"\n",
    "# Hint: The features have very different scales - some are much larger than others...\n",
    "# Hint: n_monks (5-30) vs meal_type (0-2) vs season (0-3)\n",
    "# Can you identify why the model struggles and fix the missing step?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéä COMPLETION CEREMONY\n",
    "\n",
    "When you have mastered all trials, you will have achieved:\n",
    "\n",
    "- **Multi-Feature Mastery**: Working with multi-dimensional input tensors\n",
    "- **Data Preparation Wisdom**: Scaling, splitting, and preprocessing data\n",
    "- **Optimizer Comparison**: Understanding SGD vs Adam optimization spirits\n",
    "- **Evaluation Metrics**: Using MSE, R¬≤, and other assessment tools\n",
    "- **Batch Processing**: Handling multiple predictions simultaneously\n",
    "- **Real-World Challenges**: Dealing with noisy, imperfect data\n",
    "\n",
    "Cook Oh-Pai-Timizer nods with satisfaction: *\"The grasshopper has learned that even the humblest grain of rice follows the deeper patterns of the universe. Multi-feature wisdom and optimization spirits - these are the foundations upon which greater temples are built.\"*\n",
    "\n",
    "üçö **Your Dan 1 Temple Sweeper mastery deepens!** üçö\n",
    "\n",
    "The path to Dan 2 grows clearer with each lesson learned..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}