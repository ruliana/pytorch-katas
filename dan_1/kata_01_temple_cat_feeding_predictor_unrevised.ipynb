{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nb_EJtcXY3Rh"
   },
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ruliana/pytorch-katas/blob/main/dan_1/kata_01_temple_cat_feeding_predictor_unrevised.ipynb)\n\n## üèÆ The Ancient Scroll Unfurls üèÆ\n\n**THE MYSTERIES OF SUKI'S BOWL: A LINEAR REVELATION**\n\nDan Level: 1 (Temple Sweeper) | Time: 45 minutes | Sacred Arts: Linear Regression, Gradient Descent, Loss Functions"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpTCNrRRY3Rm"
   },
   "source": "## üìú THE CHALLENGE\n\nMaster Pai-Torch sits in contemplative silence beside the temple's sacred feeding bowl, watching Suki the temple cat's daily rituals. \"Young grasshopper,\" the master begins, \"observe how the weight of food Suki requires grows with mysterious precision as the hours pass since her last meal. Yet beneath this feline mystery lies a pattern as ancient as the mountains themselves. The wise temple keepers have long known that the proper bowl weight increases steadily with each passing hour, following a sacred mathematical harmony.\"\n\n\"Your first trial as Temple Sweeper is to decode this sacred relationship,\" Master Pai-Torch continues, stroking their chin thoughtfully. \"Through the mystical arts of linear regression, you must learn to predict the exact weight of food Suki's bowl should contain based on the hours since her last meal. Master this simple relationship, and you will have taken your first step toward understanding the deeper mysteries of neural networks. But beware - even the most basic patterns require disciplined practice to master.\"\n\n## üéØ THE SACRED OBJECTIVES\n\n- [ ] **Tensor Mastery**: Create and manipulate PyTorch tensors for cat feeding data\n- [ ] **Linear Wisdom**: Implement a neural network with a single linear layer\n- [ ] **Gradient Discipline**: Master the sacred training loop with proper gradient management\n- [ ] **Loss Understanding**: Use Mean Squared Error to measure prediction accuracy\n- [ ] **Pattern Recognition**: Discover the hidden relationship between time and bowl weight\n- [ ] **Convergence Patience**: Train until your model achieves temple-worthy accuracy"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EYGnzTxTY3Rn",
    "outputId": "2dd70cf2-aef8-4743-a087-9c1931c94f0f"
   },
   "outputs": [],
   "source": "# üì¶ ALL IMPORTS AND CONFIGURATION\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom typing import Tuple\n\n# Global configuration constants\nDEFAULT_CHAOS_LEVEL = 0.1\n\nprint(\"üèÆ The Temple of Neural Networks welcomes you, Grasshopper!\")\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(\"üê± Suki stirs from her afternoon nap, sensing the approach of learning...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfENvMI0Y3Rp"
   },
   "source": "## üèπ THE SACRED DATA GENERATION SCROLL\n\n*Master Pai-Torch gestures toward the archery range*\n\n\"Before you can understand the bow, you must first understand the data.\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juC-Et0PY3Rp"
   },
   "outputs": [],
   "source": "def generate_cat_feeding_data(n_observations: int = 100, chaos_level: float = 0.1) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Generate observations of Suki's feeding patterns.\n\n    Ancient wisdom suggests: bowl_weight = 2.5 * hours_since_last_meal + 20\n    The longer since her last meal, the more food Suki needs in her bowl.\n\n    Args:\n        n_observations: Number of Suki feeding observations to simulate\n        chaos_level: Amount of feline unpredictability (0.0 = perfectly predictable cat, 1.0 = pure chaos)\n\n    Returns:\n        Tuple of (hours_since_last_meal, bowl_weight) as sacred tensors\n    \"\"\"\n    # Suki can go 0-30 hours between meals (she's very dramatic)\n    hours_since_meal = torch.rand(n_observations, 1) * 30\n\n    # The sacred relationship known to ancient cat scholars\n    base_bowl_weight = 20  # Base weight in grams for any feeding\n    weight_per_hour = 2.5  # Additional grams per hour since last meal\n\n    bowl_weight = weight_per_hour * hours_since_meal.squeeze() + base_bowl_weight\n\n    # Add feline chaos (cats are unpredictable creatures)\n    chaos = torch.randn(n_observations) * chaos_level * bowl_weight.std()\n    bowl_weight = bowl_weight + chaos\n\n    # Even mystical cats have reasonable portion limits\n    bowl_weight = torch.clamp(bowl_weight, 10, 120)\n\n    return hours_since_meal, bowl_weight.unsqueeze(1)\n\ndef visualize_cat_wisdom(hours: torch.Tensor, bowl_weight: torch.Tensor, predictions: torch.Tensor = None):\n    \"\"\"Display the sacred patterns of Suki's feeding requirements.\"\"\"\n    plt.figure(figsize=(12, 7))\n    plt.scatter(hours.numpy(), bowl_weight.numpy(), alpha=0.6, color='purple',\n                label='Actual Bowl Weight Needed')\n\n    if predictions is not None:\n        sorted_indices = torch.argsort(hours.squeeze())\n        sorted_hours = hours[sorted_indices]\n        sorted_predictions = predictions[sorted_indices]\n        plt.plot(sorted_hours.numpy(), sorted_predictions.detach().numpy(),\n                'gold', linewidth=3, label='Your Mystical Predictions')\n\n    plt.xlabel('Hours Since Last Meal (feature)')\n    plt.ylabel('Bowl Weight in Grams (target)')\n    plt.title('The Mysteries of Temple Cat Feeding Requirements')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.ylim(0, 120)\n    plt.show()\n\n# Generate the sacred data\nhours_since_meal, bowl_weight = generate_cat_feeding_data(n_observations=100)\n\nprint(f\"üìä Generated {len(hours_since_meal)} observations of Suki's feeding patterns\")\nprint(f\"‚è∞ Hours since meal range: {hours_since_meal.min():.1f} to {hours_since_meal.max():.1f}\")\nprint(f\"üçΩÔ∏è Bowl weight range: {bowl_weight.min():.1f} to {bowl_weight.max():.1f} grams\")\n\n# Visualize the sacred patterns\nvisualize_cat_wisdom(hours_since_meal, bowl_weight)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kkdux47jY3Rq"
   },
   "source": [
    "## üíÉ FIRST MOVEMENTS: THE NEURAL NETWORK FOUNDATION\n",
    "\n",
    "*Master Pai-Torch nods approvingly*\n",
    "\n",
    "\"Now that you have witnessed the sacred data, it is time to craft your first neural network. Though simple in form, this linear layer contains the essence of all deeper mysteries. Complete the missing sacred techniques below.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uaNpsaSyY3Rq"
   },
   "outputs": [],
   "source": "class CatBowlPredictor(nn.Module):\n    \"\"\"A mystical artifact for understanding feline feeding requirements.\"\"\"\n\n    def __init__(self, input_features: int = 1):\n        super(CatBowlPredictor, self).__init__()\n        # TODO: Create the Linear layer\n        # Hint: torch.nn.Linear transforms input energy into output wisdom\n        # It needs input_features and output_features (how many predictions?)\n        self.linear = None\n\n    def forward(self, features: torch.Tensor) -> torch.Tensor:\n        \"\"\"Channel your understanding through the mystical network.\"\"\"\n        # TODO: Pass the input through your Linear layer\n        # Remember: even cats follow mathematical laws\n        return None\n\ndef train(model: nn.Module, features: torch.Tensor, target: torch.Tensor, epochs: int = 4_000) -> list:\n    \"\"\"\n    Train the cat bowl weight prediction model.\n\n    Returns:\n        List of loss values during training\n    \"\"\"\n    # TODO: Choose your loss calculation method\n    # Hint: Mean Squared Error is favored by the ancient masters\n    criterion = None\n\n    # TODO: Choose your parameter updating method\n    # Hint: SGD (Stochastic Gradient Descent) is the traditional path\n    optimizer = None\n\n    losses = []\n\n    for epoch in range(epochs):\n        # TODO: CRITICAL - Clear the gradient spirits from previous cycle\n        # Hint: The spirits accumulate if not banished properly\n        # This is the most common mistake in PyTorch training!\n\n        # TODO: Forward pass - get predictions\n        predictions = None\n\n        # TODO: Compute the loss\n        loss = None\n\n        # TODO: Backward pass - compute gradients\n        # Hint: Loss knows how to compute its own gradients\n\n        # TODO: Update parameters\n        # Hint: The optimizer knows how to update using the gradients\n\n        losses.append(loss.item())\n\n        # Report progress to Master Pai-Torch\n        if (epoch + 1) % 100 == 0:\n            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n            if loss.item() < 10:\n                print(\"üí´ The Gradient Spirits smile upon your progress!\")\n\n    return losses\n\n# Create your first neural network\nmodel = CatBowlPredictor(input_features=1)\nprint(\"üß† Your neural network has been born!\")\nprint(f\"Model structure: {model}\")\nprint(f\"Initial parameters: Weight={model.linear.weight.item():.3f}, Bias={model.linear.bias.item():.3f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjgngVwcY3Rr"
   },
   "source": [
    "## üéØ UNLEASH THE TRAINING RITUAL\n",
    "\n",
    "*Master Pai-Torch places a weathered hand on your shoulder*\n",
    "\n",
    "\"Now comes the sacred moment, grasshopper. Train your network with the feeding data and witness the emergence of wisdom from randomness.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8GqAdbcFY3Rs"
   },
   "outputs": [],
   "source": "# Begin the training ritual\nprint(\"üî• Beginning the sacred training ritual...\")\nprint(\"Master Pai-Torch whispers: 'Watch the loss decrease, young one. This is the dance of learning.'\")\n\n# TODO: Train your model using the function above\n# Use: hours_since_meal, bowl_weight, and appropriate epochs/learning_rate\nloss_history = None\n\n# Visualize the training progress\nplt.figure(figsize=(10, 6))\nplt.plot(loss_history)\nplt.title('The Sacred Dance of Loss Reduction')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.grid(True, alpha=0.3)\nplt.show()\n\n# Examine the learned parameters\nlearned_weight = model.linear.weight.item()\nlearned_bias = model.linear.bias.item()\nprint(f\"\\nüéä Training Complete! üéä\")\nprint(f\"Learned relationship: bowl_weight = {learned_weight:.3f} √ó hours + {learned_bias:.3f}\")\nprint(f\"True relationship: bowl_weight = 2.500 √ó hours + 20.000\")\nprint(f\"Weight accuracy: {abs(learned_weight - 2.5):.3f} away from true value\")\nprint(f\"Bias accuracy: {abs(learned_bias - 20):.3f} away from true value\")\n\n# Generate predictions and visualize\nwith torch.no_grad():\n    predictions = model(hours_since_meal)\n\nprint(\"\\nüîÆ Visualizing your mystical predictions...\")\nvisualize_cat_wisdom(hours_since_meal, bowl_weight, predictions)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfL-EV_TY3Rt"
   },
   "source": [
    "## ‚ö° THE TRIALS OF MASTERY\n",
    "\n",
    "*Master Pai-Torch examines your work with ancient eyes*\n",
    "\n",
    "\"Your first steps show promise, grasshopper. But true mastery must be tested through sacred trials.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFXq_hyaY3Rt"
   },
   "outputs": [],
   "source": "# TRIALS OF MASTERY\nprint(\"‚ö° TRIAL 1: BASIC MASTERY\")\n\n# Check your progress\nfinal_loss = loss_history[-1] if loss_history else float('inf')\nweight_accuracy = abs(learned_weight - 2.5) < 0.5\nbias_accuracy = abs(learned_bias - 20) < 5\n\n# Check if loss decreases consistently (last loss < first loss by significant margin)\nloss_decreases = len(loss_history) > 100 and loss_history[-1] < loss_history[99] * 0.9\n\n# Check if predictions form a clean line (R¬≤ > 0.8)\nwith torch.no_grad():\n    predictions = model(hours_since_meal)\n    y_mean = bowl_weight.mean()\n    ss_tot = ((bowl_weight - y_mean) ** 2).sum()\n    ss_res = ((bowl_weight - predictions) ** 2).sum()\n    r_squared = 1 - (ss_res / ss_tot)\n    clean_line = r_squared > 0.8\n\n# Trial 1 checkboxes\nloss_check = \"‚úÖ\" if loss_decreases else \"‚ùå\"\nweight_bias_check = \"‚úÖ\" if (weight_accuracy and bias_accuracy) else \"‚ùå\"\nline_check = \"‚úÖ\" if clean_line else \"‚ùå\"\n\nprint(f\"- {loss_check} Loss decreases consistently (no angry Gradient Spirits)\")\nprint(f\"- {weight_bias_check} Model weight approximately 2.5 (¬±0.5), bias around 20 (¬±5)\")\nprint(f\"- {line_check} Predictions form a clean line through the scattered data\")\n\n# Trial 2: Understanding Test\nprint(\"\\n‚ö° TRIAL 2: UNDERSTANDING TEST\")\n\n# Test prediction shapes\ntest_features = torch.tensor([[5.0], [10.0], [20.0]])\nwith torch.no_grad():\n    test_predictions = model(test_features)\n\nshapes_correct = test_predictions.shape == (3, 1)\nweight_reasonable = 2.0 <= learned_weight <= 3.0\nbias_reasonable = 15 <= learned_bias <= 25\n\n# Test prediction reasonableness - bowl weights for 5, 10, 20 hours\ntest_pred_values = test_predictions.squeeze().tolist()\nexpected_approx = [2.5 * 5 + 20, 2.5 * 10 + 20, 2.5 * 20 + 20]  # [32.5, 45, 70] grams\npredictions_reasonable = all(abs(pred - exp) <= 10 for pred, exp in zip(test_pred_values, expected_approx))\n\n# Trial 2 checkboxes\nshapes_check = \"‚úÖ\" if shapes_correct else \"‚ùå\"\nweight_param_check = \"‚úÖ\" if weight_reasonable else \"‚ùå\"\nbias_param_check = \"‚úÖ\" if bias_reasonable else \"‚ùå\"\npred_check = \"‚úÖ\" if predictions_reasonable else \"‚ùå\"\n\nprint(f\"- {shapes_check} Tensor shapes align with the sacred geometry\")\nprint(f\"- {weight_param_check} Weight parameter reflects feline feeding wisdom\")\nprint(f\"- {bias_param_check} Bias parameter captures base bowl weight\")\nprint(f\"- {pred_check} Predictions are reasonable for test inputs\")\n\n# Your Performance section\nprint(f\"\\nüìä Your Performance:\")\nprint(f\"- Weight accuracy: {learned_weight:.3f} {'(PASS)' if weight_accuracy else '(FAIL)'}\")\nprint(f\"- Bias accuracy: {learned_bias:.3f} {'(PASS)' if bias_accuracy else '(FAIL)'}\")\n\n# Overall success check\ntrial1_passed = loss_decreases and weight_accuracy and bias_accuracy and clean_line\ntrial2_passed = shapes_correct and weight_reasonable and bias_reasonable and predictions_reasonable\n\nif trial1_passed and trial2_passed:\n    print(\"\\nüéâ Master Pai-Torch nods with approval - your understanding grows!\")\n    print(\"\\nüèÜ Congratulations! You have passed the basic trials of the Temple Sweeper!\")\n    print(\"üê± Suki purrs approvingly - your neural network has learned her sacred feeding patterns.\")\nelse:\n    print(\"\\nü§î The path to mastery requires more practice. Consider adjusting your training parameters.\")\n    print(\"üí° Hint: Try different learning rates, more epochs, or review your code for errors.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wav0AdVGY3Ru"
   },
   "source": "## üå∏ THE FOUR PATHS OF MASTERY: PROGRESSIVE EXTENSIONS\n\n*Master Pai-Torch gestures toward four different pathways leading deeper into the temple.*\n\n\"You have learned the fundamental way, grasshopper. But mastery comes through exploring the branching paths.\"\n\n* ‚è±Ô∏è Reduce the number of epochs. How well does the model fit?\n* üöÄ Increase or decrease the learning rate in SGD (default is 0.001). What happens to the loss? What if you adjust the number of epochs? Can you make it converge?\n* üå™Ô∏è Increase the chaos in Suki's data. How chaotic can you make it and still get reasonable results?\n* üìä Increase or decrease the number of observations in Suki's data. What's the minimum amount needed for learning? What happens if you increase it? Does it affect the required number of epochs or the learning rate?"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPbQKJKFY3Rz"
   },
   "source": "## üèÜ COMPLETION CEREMONY\n\n*Master Pai-Torch rises and bows respectfully*\n\n\"Congratulations, young grasshopper. You have successfully completed your first kata in the Temple of Neural Networks. Through Suki's simple feeding requirements, you have learned the fundamental mysteries that underlie all neural arts:\n\n**Sacred Knowledge Acquired:**\n- **Tensor Mastery**: You can create and manipulate PyTorch tensors with confidence\n- **Linear Wisdom**: You understand how neural networks transform input to output\n- **Gradient Discipline**: You have mastered the sacred training loop and gradient management\n- **Loss Understanding**: You can measure and minimize prediction errors\n\n**Final Wisdom:**\nRemember always: every complex neural network, no matter how sophisticated, is built upon the simple principles you practiced here. The gradient flows, the loss decreases, and wisdom emerges from the dance between prediction and reality.\n\nüê± *Suki purrs approvingly from her feeding bowl, as if to say: \"You are ready for greater challenges, young neural warrior.\"*\n\nüèÆ **May your gradients flow smoothly and your losses converge swiftly!** üèÆ\""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}