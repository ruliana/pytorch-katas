{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ruliana/pytorch-katas/blob/main/dan_1/kata_05_temple_visitor_spiritual_observer_unrevised.ipynb)\n",
    "\n",
    "## 🏮 The Ancient Scroll Unfurls 🏮\n",
    "\n",
    "# THE MASTER'S EYE: CATEGORIZING THE SPIRITUAL JOURNEY\n",
    "Dan Level: 1 (Temple Sweeper) | Time: 45 minutes | Sacred Arts: Multi-variable Features, Multi-class Classification, Softmax Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📜 THE CHALLENGE\n",
    "\n",
    "Master Pai-Torch sits in silent observation at the temple entrance, watching the endless stream of visitors arrive for guidance. Through decades of patient study, the ancient master has learned to categorize each seeker into one of three sacred stages: **nervous novices** who fidget and rush with endless questions, **steady practitioners** who move with growing confidence and measured inquiry, and **serene masters** who glide with graceful slowness, breathing deeply, rarely needing to ask what they already know within.\n",
    "\n",
    "\"Grasshopper,\" Master Pai-Torch says, eyes still fixed on a visitor approaching the gates, \"the untrained eye sees only people walking. But observe closely—the way one moves reveals the state of one's inner cultivation. Their walking speed speaks of anxiety or calm, their posture shows discipline or distraction, their breathing patterns reveal tension or peace, and their questioning frequency exposes wisdom or confusion. Today, you shall learn to see as the masters see, using the mystical arts of multi-variable classification to peer into the soul through observable behavior.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 THE SACRED OBJECTIVES\n",
    "\n",
    "- [ ] Master the creation of synthetic data with multiple meaningful features\n",
    "- [ ] Build a neural network that processes multiple input variables simultaneously\n",
    "- [ ] Implement multi-class classification using softmax activation\n",
    "- [ ] Understand how different features contribute to classification decisions\n",
    "- [ ] Visualize the relationship between multiple behavioral patterns and spiritual development\n",
    "- [ ] Learn to interpret model confidence across multiple classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 FIRST CELL - ALL IMPORTS AND CONFIGURATION\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import seaborn as sns\n",
    "\n",
    "# Set reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Global configuration constants\n",
    "DEFAULT_CHAOS_LEVEL = 0.15\n",
    "SACRED_SEED = 42\n",
    "N_FEATURES = 4  # walking_speed, posture_score, question_frequency, breathing_depth\n",
    "N_CLASSES = 3   # nervous_novice=0, steady_practitioner=1, serene_master=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧘 THE SACRED DATA GENERATION SCROLL\n",
    "\n",
    "def generate_temple_visitor_data(n_visitors: int = 300, chaos_level: float = 0.15,\n",
    "                               sacred_seed: int = 42) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Generate observations of temple visitors and their spiritual development stage.\n",
    "    \n",
    "    Master Pai-Torch's ancient wisdom reveals these patterns:\n",
    "    - Nervous Novices: Fast walking (0.8-1.2), poor posture (0.2-0.5), many questions (8-15), shallow breathing (0.3-0.6)\n",
    "    - Steady Practitioners: Moderate walking (0.5-0.8), good posture (0.6-0.8), some questions (3-8), regular breathing (0.6-0.8)\n",
    "    - Serene Masters: Slow walking (0.2-0.5), excellent posture (0.8-1.0), few questions (0-3), deep breathing (0.8-1.0)\n",
    "    \n",
    "    Args:\n",
    "        n_visitors: Number of temple visitors to observe\n",
    "        chaos_level: Amount of individual variation (0.0 = perfectly predictable, 1.0 = pure chaos)\n",
    "        sacred_seed: Ensures consistent observations\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (behavioral_features, spiritual_stage_labels) as tensors\n",
    "        Features: [walking_speed, posture_score, question_frequency, breathing_depth]\n",
    "        Labels: 0=Nervous Novice, 1=Steady Practitioner, 2=Serene Master\n",
    "    \"\"\"\n",
    "    torch.manual_seed(sacred_seed)\n",
    "    \n",
    "    # Create equal representation of each spiritual stage\n",
    "    visitors_per_stage = n_visitors // N_CLASSES\n",
    "    remainder = n_visitors % N_CLASSES\n",
    "    \n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    # Generate Nervous Novices (label = 0)\n",
    "    n_novices = visitors_per_stage + (1 if remainder > 0 else 0)\n",
    "    walking_speed = torch.uniform(0.8, 1.2, (n_novices,))\n",
    "    posture_score = torch.uniform(0.2, 0.5, (n_novices,))\n",
    "    question_freq = torch.uniform(8.0, 15.0, (n_novices,))\n",
    "    breathing_depth = torch.uniform(0.3, 0.6, (n_novices,))\n",
    "    \n",
    "    novice_features = torch.stack([walking_speed, posture_score, question_freq, breathing_depth], dim=1)\n",
    "    novice_labels = torch.zeros(n_novices, dtype=torch.long)\n",
    "    \n",
    "    features_list.append(novice_features)\n",
    "    labels_list.append(novice_labels)\n",
    "    \n",
    "    # Generate Steady Practitioners (label = 1)\n",
    "    n_practitioners = visitors_per_stage + (1 if remainder > 1 else 0)\n",
    "    walking_speed = torch.uniform(0.5, 0.8, (n_practitioners,))\n",
    "    posture_score = torch.uniform(0.6, 0.8, (n_practitioners,))\n",
    "    question_freq = torch.uniform(3.0, 8.0, (n_practitioners,))\n",
    "    breathing_depth = torch.uniform(0.6, 0.8, (n_practitioners,))\n",
    "    \n",
    "    practitioner_features = torch.stack([walking_speed, posture_score, question_freq, breathing_depth], dim=1)\n",
    "    practitioner_labels = torch.ones(n_practitioners, dtype=torch.long)\n",
    "    \n",
    "    features_list.append(practitioner_features)\n",
    "    labels_list.append(practitioner_labels)\n",
    "    \n",
    "    # Generate Serene Masters (label = 2)\n",
    "    n_masters = visitors_per_stage\n",
    "    walking_speed = torch.uniform(0.2, 0.5, (n_masters,))\n",
    "    posture_score = torch.uniform(0.8, 1.0, (n_masters,))\n",
    "    question_freq = torch.uniform(0.0, 3.0, (n_masters,))\n",
    "    breathing_depth = torch.uniform(0.8, 1.0, (n_masters,))\n",
    "    \n",
    "    master_features = torch.stack([walking_speed, posture_score, question_freq, breathing_depth], dim=1)\n",
    "    master_labels = torch.full((n_masters,), 2, dtype=torch.long)\n",
    "    \n",
    "    features_list.append(master_features)\n",
    "    labels_list.append(master_labels)\n",
    "    \n",
    "    # Combine all data\n",
    "    all_features = torch.cat(features_list, dim=0)\n",
    "    all_labels = torch.cat(labels_list, dim=0)\n",
    "    \n",
    "    # Add natural variation (individual differences)\n",
    "    noise = torch.randn_like(all_features) * chaos_level * all_features.std(dim=0)\n",
    "    all_features = all_features + noise\n",
    "    \n",
    "    # Ensure features stay within reasonable bounds\n",
    "    all_features = torch.clamp(all_features, min=0.0)\n",
    "    all_features[:, 2] = torch.clamp(all_features[:, 2], max=20.0)  # Max 20 questions\n",
    "    all_features[:, [0, 1, 3]] = torch.clamp(all_features[:, [0, 1, 3]], max=1.5)  # Reasonable maximums\n",
    "    \n",
    "    # Shuffle the data\n",
    "    shuffle_indices = torch.randperm(n_visitors)\n",
    "    all_features = all_features[shuffle_indices]\n",
    "    all_labels = all_labels[shuffle_indices]\n",
    "    \n",
    "    return all_features, all_labels\n",
    "\n",
    "def visualize_spiritual_wisdom(features: torch.Tensor, labels: torch.Tensor, \n",
    "                             predictions: torch.Tensor = None, title_suffix: str = \"\"):\n",
    "    \"\"\"\n",
    "    Display the sacred patterns of spiritual development through Master Pai-Torch's eyes.\n",
    "    \"\"\"\n",
    "    feature_names = ['Walking Speed', 'Posture Score', 'Questions/Hour', 'Breathing Depth']\n",
    "    stage_names = ['Nervous Novice', 'Steady Practitioner', 'Serene Master']\n",
    "    colors = ['red', 'orange', 'purple']\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle(f'Master Pai-Torch\\'s Spiritual Observation {title_suffix}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot feature distributions for each class\n",
    "    for i, feature_name in enumerate(feature_names):\n",
    "        ax = axes[i//2, i%2] if i < 4 else None\n",
    "        if ax is None:\n",
    "            continue\n",
    "            \n",
    "        for stage_idx, (stage_name, color) in enumerate(zip(stage_names, colors)):\n",
    "            stage_mask = labels == stage_idx\n",
    "            stage_data = features[stage_mask, i].numpy()\n",
    "            ax.hist(stage_data, alpha=0.6, color=color, label=stage_name, bins=15)\n",
    "        \n",
    "        ax.set_xlabel(feature_name)\n",
    "        ax.set_ylabel('Number of Visitors')\n",
    "        ax.set_title(f'Distribution: {feature_name}')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Feature correlation heatmap\n",
    "    ax = axes[1, 2]\n",
    "    correlation_matrix = torch.corrcoef(features.T).numpy()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "                xticklabels=feature_names, yticklabels=feature_names, ax=ax)\n",
    "    ax.set_title('Feature Correlations\\n(Master\\'s Insights)')\n",
    "    \n",
    "    # 3D scatter plot of selected features\n",
    "    ax = fig.add_subplot(2, 3, 5, projection='3d')\n",
    "    for stage_idx, (stage_name, color) in enumerate(zip(stage_names, colors)):\n",
    "        stage_mask = labels == stage_idx\n",
    "        stage_features = features[stage_mask]\n",
    "        ax.scatter(stage_features[:, 0], stage_features[:, 1], stage_features[:, 3],\n",
    "                  c=color, label=stage_name, alpha=0.6, s=30)\n",
    "    \n",
    "    ax.set_xlabel('Walking Speed')\n",
    "    ax.set_ylabel('Posture Score')\n",
    "    ax.set_zlabel('Breathing Depth')\n",
    "    ax.set_title('3D Spiritual Landscape')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # If predictions are provided, show confusion matrix\n",
    "    if predictions is not None:\n",
    "        from sklearn.metrics import confusion_matrix, classification_report\n",
    "        \n",
    "        # Convert predictions to class labels\n",
    "        pred_labels = torch.argmax(predictions, dim=1)\n",
    "        \n",
    "        # Create confusion matrix\n",
    "        cm = confusion_matrix(labels.numpy(), pred_labels.numpy())\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=stage_names, yticklabels=stage_names)\n",
    "        plt.title('Confusion Matrix: Master Pai-Torch\\'s Accuracy')\n",
    "        plt.xlabel('Predicted Spiritual Stage')\n",
    "        plt.ylabel('True Spiritual Stage')\n",
    "        plt.show()\n",
    "        \n",
    "        # Print classification report\n",
    "        print(\"\\n🧘 MASTER PAI-TORCH'S DETAILED ASSESSMENT:\")\n",
    "        print(classification_report(labels.numpy(), pred_labels.numpy(), \n",
    "                                  target_names=stage_names, digits=3))\n",
    "\n",
    "# Generate and visualize the sacred data\n",
    "print(\"🏮 Master Pai-Torch observes the temple visitors...\")\n",
    "features, labels = generate_temple_visitor_data(n_visitors=300, chaos_level=0.15)\n",
    "\n",
    "print(f\"\\n📊 OBSERVATIONS RECORDED:\")\n",
    "print(f\"- Total visitors observed: {len(features)}\")\n",
    "print(f\"- Features per visitor: {features.shape[1]}\")\n",
    "print(f\"- Nervous Novices: {(labels == 0).sum().item()}\")\n",
    "print(f\"- Steady Practitioners: {(labels == 1).sum().item()}\")\n",
    "print(f\"- Serene Masters: {(labels == 2).sum().item()}\")\n",
    "\n",
    "visualize_spiritual_wisdom(features, labels, title_suffix=\"(Original Data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💫 THE SPIRITUAL CLASSIFIER\n",
    "\n",
    "Now you must build the mystical artifact that can peer into a visitor's soul through their behavior patterns. Master Pai-Torch whispers ancient wisdom about multi-class classification..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔮 THE SPIRITUAL OBSERVATION NETWORK\n",
    "\n",
    "class SpiritualObserver(nn.Module):\n",
    "    \"\"\"A mystical network that categorizes temple visitors by their spiritual development.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_features: int = 4, hidden_size: int = 8, num_classes: int = 3):\n",
    "        super(SpiritualObserver, self).__init__()\n",
    "        \n",
    "        # TODO: Create the neural architecture for spiritual observation\n",
    "        # Hint: You'll need layers to process multiple features and output class probabilities\n",
    "        \n",
    "        # First hidden layer: transforms behavioral features into hidden wisdom\n",
    "        self.hidden = None  # TODO: nn.Linear(input_features, hidden_size)\n",
    "        \n",
    "        # Output layer: transforms hidden wisdom into spiritual stage probabilities\n",
    "        self.classifier = None  # TODO: nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()  # For hidden layer non-linearity\n",
    "        # NOTE: We don't need to add softmax here - CrossEntropyLoss includes it!\n",
    "    \n",
    "    def forward(self, features: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Channel behavioral observations through the network of spiritual wisdom.\n",
    "        \n",
    "        Args:\n",
    "            features: Tensor of shape (batch_size, 4) containing behavioral measurements\n",
    "        \n",
    "        Returns:\n",
    "            raw_scores: Tensor of shape (batch_size, 3) with raw class scores (logits)\n",
    "        \"\"\"\n",
    "        # TODO: Forward pass through the network\n",
    "        # Hint: features -> hidden layer -> ReLU -> output layer\n",
    "        \n",
    "        # Process through hidden layer with non-linear activation\n",
    "        hidden_wisdom = None  # TODO: Apply hidden layer and ReLU activation\n",
    "        \n",
    "        # Generate final class scores (logits)\n",
    "        raw_scores = None  # TODO: Apply classifier layer\n",
    "        \n",
    "        return raw_scores\n",
    "\n",
    "def train_spiritual_observer(model: nn.Module, features: torch.Tensor, labels: torch.Tensor,\n",
    "                           epochs: int = 1000, learning_rate: float = 0.01) -> tuple:\n",
    "    \"\"\"\n",
    "    Train the spiritual observer to recognize different stages of development.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (loss_history, accuracy_history)\n",
    "    \"\"\"\n",
    "    # TODO: Choose the appropriate loss function for multi-class classification\n",
    "    # Hint: CrossEntropyLoss is perfect for this - it combines softmax and negative log likelihood\n",
    "    criterion = None\n",
    "    \n",
    "    # TODO: Choose your optimization method\n",
    "    # Hint: Adam works well for multi-class problems\n",
    "    optimizer = None\n",
    "    \n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # TODO: CRITICAL - Clear the gradient spirits from the previous cycle\n",
    "        \n",
    "        # TODO: Forward pass - get class score predictions\n",
    "        raw_scores = None\n",
    "        \n",
    "        # TODO: Compute the loss\n",
    "        loss = None\n",
    "        \n",
    "        # TODO: Backward pass - compute gradients\n",
    "        \n",
    "        # TODO: Update parameters\n",
    "        \n",
    "        # Calculate accuracy for this epoch\n",
    "        with torch.no_grad():\n",
    "            predicted_classes = torch.argmax(raw_scores, dim=1)\n",
    "            accuracy = (predicted_classes == labels).float().mean().item()\n",
    "        \n",
    "        loss_history.append(loss.item())\n",
    "        accuracy_history.append(accuracy)\n",
    "        \n",
    "        # Report progress to Master Pai-Torch\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}')\n",
    "            if accuracy > 0.8:\n",
    "                print(\"🌸 Master Pai-Torch observes: 'Your perception grows clearer, Grasshopper.'\")\n",
    "    \n",
    "    return loss_history, accuracy_history\n",
    "\n",
    "def get_class_probabilities(model: nn.Module, features: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Get the probability distribution over classes for each visitor.\n",
    "    \n",
    "    Returns:\n",
    "        Tensor of shape (batch_size, 3) with probabilities summing to 1 for each row\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        raw_scores = model(features)\n",
    "        # TODO: Apply softmax to convert raw scores to probabilities\n",
    "        # Hint: torch.softmax(raw_scores, dim=1)\n",
    "        probabilities = None\n",
    "    return probabilities\n",
    "\n",
    "# Create and display the spiritual observer\n",
    "model = SpiritualObserver(input_features=4, hidden_size=8, num_classes=3)\n",
    "print(\"🔮 SPIRITUAL OBSERVER ARCHITECTURE:\")\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters to learn: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚗️ THE TRAINING RITUAL\n",
    "\n",
    "Time to train your spiritual observer! Watch as it learns to distinguish between the three sacred stages of development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🏋️ TRAINING THE MYSTICAL PERCEPTION\n",
    "\n",
    "print(\"🧘 Master Pai-Torch begins the training ritual...\")\n",
    "\n",
    "# Train the model\n",
    "loss_history, accuracy_history = train_spiritual_observer(\n",
    "    model, features, labels, epochs=1000, learning_rate=0.01\n",
    ")\n",
    "\n",
    "# Visualize training progress\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(loss_history, color='red', alpha=0.7)\n",
    "plt.title('Loss During Training\\n(Spiritual Confusion Decreasing)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cross-Entropy Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(accuracy_history, color='green', alpha=0.7)\n",
    "plt.title('Accuracy During Training\\n(Spiritual Insight Growing)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification Accuracy')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Final accuracy distribution\n",
    "plt.subplot(1, 3, 3)\n",
    "final_predictions = get_class_probabilities(model, features)\n",
    "predicted_labels = torch.argmax(final_predictions, dim=1)\n",
    "stage_names = ['Nervous\\nNovice', 'Steady\\nPractitioner', 'Serene\\nMaster']\n",
    "\n",
    "# Count correct predictions per class\n",
    "correct_per_class = []\n",
    "total_per_class = []\n",
    "for class_idx in range(3):\n",
    "    class_mask = labels == class_idx\n",
    "    correct_mask = (predicted_labels == labels) & class_mask\n",
    "    correct_per_class.append(correct_mask.sum().item())\n",
    "    total_per_class.append(class_mask.sum().item())\n",
    "\n",
    "accuracies = [c/t for c, t in zip(correct_per_class, total_per_class)]\n",
    "colors = ['red', 'orange', 'purple']\n",
    "\n",
    "bars = plt.bar(stage_names, accuracies, color=colors, alpha=0.7)\n",
    "plt.title('Per-Class Accuracy\\n(Master\\'s Assessment)')\n",
    "plt.ylabel('Classification Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "             f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n🎯 FINAL TRAINING RESULTS:\")\n",
    "print(f\"- Final Loss: {loss_history[-1]:.4f}\")\n",
    "print(f\"- Final Accuracy: {accuracy_history[-1]:.4f}\")\n",
    "print(f\"- Best Accuracy Achieved: {max(accuracy_history):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 ANALYZING THE MASTER'S VISION\n",
    "\n",
    "Let's examine how well your spiritual observer has learned to categorize temple visitors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎭 DETAILED ANALYSIS OF SPIRITUAL PERCEPTION\n",
    "\n",
    "# Get final predictions\n",
    "final_predictions = get_class_probabilities(model, features)\n",
    "predicted_labels = torch.argmax(final_predictions, dim=1)\n",
    "\n",
    "# Show comprehensive results with confusion matrix\n",
    "visualize_spiritual_wisdom(features, labels, final_predictions, \"(Trained Model)\")\n",
    "\n",
    "# Analyze some specific examples\n",
    "print(\"\\n🔮 MASTER PAI-TORCH'S SPECIFIC OBSERVATIONS:\")\n",
    "print(\"\\nExamining individual visitors...\")\n",
    "\n",
    "stage_names = ['Nervous Novice', 'Steady Practitioner', 'Serene Master']\n",
    "feature_names = ['Walking Speed', 'Posture Score', 'Questions/Hour', 'Breathing Depth']\n",
    "\n",
    "# Show 5 examples from each class\n",
    "for true_class in range(3):\n",
    "    class_mask = labels == true_class\n",
    "    class_indices = torch.where(class_mask)[0][:5]  # First 5 examples\n",
    "    \n",
    "    print(f\"\\n--- {stage_names[true_class].upper()} EXAMPLES ---\")\n",
    "    \n",
    "    for idx in class_indices:\n",
    "        true_label = labels[idx].item()\n",
    "        pred_label = predicted_labels[idx].item()\n",
    "        pred_probs = final_predictions[idx]\n",
    "        visitor_features = features[idx]\n",
    "        \n",
    "        print(f\"\\nVisitor {idx.item()}:\")\n",
    "        print(f\"  Behaviors: {[f'{name}: {val:.3f}' for name, val in zip(feature_names, visitor_features)]}\")\n",
    "        print(f\"  True stage: {stage_names[true_label]}\")\n",
    "        print(f\"  Predicted: {stage_names[pred_label]} {'✓' if pred_label == true_label else '✗'}\")\n",
    "        print(f\"  Confidence: {pred_probs[pred_label]:.3f}\")\n",
    "        print(f\"  All probabilities: {[f'{name}: {prob:.3f}' for name, prob in zip(stage_names, pred_probs)]}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "print(\"\\n\\n🧠 UNDERSTANDING WHAT THE MODEL LEARNED:\")\n",
    "print(\"\\nHidden layer weights (how features combine):\")\n",
    "hidden_weights = model.hidden.weight.data\n",
    "print(f\"Shape: {hidden_weights.shape} (8 hidden neurons, 4 input features)\")\n",
    "\n",
    "# Show which features each hidden neuron focuses on\n",
    "for neuron_idx in range(hidden_weights.shape[0]):\n",
    "    neuron_weights = hidden_weights[neuron_idx]\n",
    "    dominant_feature = torch.argmax(torch.abs(neuron_weights)).item()\n",
    "    print(f\"Hidden neuron {neuron_idx}: Most sensitive to {feature_names[dominant_feature]} (weight: {neuron_weights[dominant_feature]:.3f})\")\n",
    "\n",
    "print(\"\\nOutput layer weights (how hidden neurons vote for classes):\")\n",
    "output_weights = model.classifier.weight.data\n",
    "print(f\"Shape: {output_weights.shape} (3 classes, 8 hidden neurons)\")\n",
    "\n",
    "for class_idx, class_name in enumerate(stage_names):\n",
    "    class_weights = output_weights[class_idx]\n",
    "    strongest_neuron = torch.argmax(torch.abs(class_weights)).item()\n",
    "    print(f\"{class_name}: Strongest connection to hidden neuron {strongest_neuron} (weight: {class_weights[strongest_neuron]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡ THE TRIALS OF MASTERY\n",
    "\n",
    "Master Pai-Torch evaluates your spiritual observation skills through sacred trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚡ THE TRIALS OF MASTERY\n",
    "\n",
    "def test_your_wisdom(model):\n",
    "    \"\"\"Master Pai-Torch's evaluation of your spiritual observation mastery.\"\"\"\n",
    "    \n",
    "    print(\"🧘 Master Pai-Torch tests your understanding...\\n\")\n",
    "    \n",
    "    # Test 1: Model architecture validation\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    expected_params = 4*8 + 8 + 8*3 + 3  # input->hidden + hidden_bias + hidden->output + output_bias\n",
    "    assert total_params == expected_params, f\"Expected {expected_params} parameters, got {total_params}\"\n",
    "    print(\"✓ Architecture Test: Your network structure is sound\")\n",
    "    \n",
    "    # Test 2: Output shape validation\n",
    "    test_features = torch.randn(5, 4)  # 5 visitors, 4 features each\n",
    "    with torch.no_grad():\n",
    "        raw_outputs = model(test_features)\n",
    "        probabilities = torch.softmax(raw_outputs, dim=1)\n",
    "    \n",
    "    assert raw_outputs.shape == (5, 3), f\"Expected output shape (5, 3), got {raw_outputs.shape}\"\n",
    "    print(\"✓ Output Shape Test: Your predictions have correct dimensions\")\n",
    "    \n",
    "    # Test 3: Probability validation\n",
    "    prob_sums = probabilities.sum(dim=1)\n",
    "    assert torch.allclose(prob_sums, torch.ones(5), atol=1e-6), \"Probabilities don't sum to 1!\"\n",
    "    print(\"✓ Probability Test: Your softmax outputs valid probabilities\")\n",
    "    \n",
    "    # Test 4: Training effectiveness\n",
    "    final_accuracy = accuracy_history[-1]\n",
    "    assert final_accuracy > 0.7, f\"Accuracy {final_accuracy:.3f} too low - the spirits are not pleased\"\n",
    "    print(f\"✓ Learning Test: Your model achieved {final_accuracy:.3f} accuracy\")\n",
    "    \n",
    "    # Test 5: Loss convergence\n",
    "    final_loss = loss_history[-1]\n",
    "    initial_loss = loss_history[0]\n",
    "    improvement = (initial_loss - final_loss) / initial_loss\n",
    "    assert improvement > 0.5, f\"Loss improved by only {improvement:.1%} - more training needed\"\n",
    "    print(f\"✓ Convergence Test: Loss improved by {improvement:.1%}\")\n",
    "    \n",
    "    # Test 6: Feature processing\n",
    "    # Create extreme examples to test if model responds appropriately\n",
    "    extreme_novice = torch.tensor([[1.2, 0.2, 15.0, 0.3]])  # Fast, bad posture, many questions, shallow breathing\n",
    "    extreme_master = torch.tensor([[0.2, 1.0, 0.0, 1.0]])    # Slow, perfect posture, no questions, deep breathing\n",
    "    \n",
    "    novice_probs = get_class_probabilities(model, extreme_novice)\n",
    "    master_probs = get_class_probabilities(model, extreme_master)\n",
    "    \n",
    "    novice_prediction = torch.argmax(novice_probs, dim=1).item()\n",
    "    master_prediction = torch.argmax(master_probs, dim=1).item()\n",
    "    \n",
    "    # These might not always be perfect due to randomness, but let's check general behavior\n",
    "    if novice_prediction == 0:  # Correctly identified as novice\n",
    "        print(\"✓ Extreme Example Test: Correctly identified extreme novice\")\n",
    "    else:\n",
    "        print(f\"⚠ Extreme Example: Extreme novice classified as {stage_names[novice_prediction]}\")\n",
    "    \n",
    "    if master_prediction == 2:  # Correctly identified as master\n",
    "        print(\"✓ Extreme Example Test: Correctly identified extreme master\")\n",
    "    else:\n",
    "        print(f\"⚠ Extreme Example: Extreme master classified as {stage_names[master_prediction]}\")\n",
    "    \n",
    "    print(\"\\n🎉 Master Pai-Torch nods with deep approval...\")\n",
    "    print('\"Your eyes now see beyond the surface, Grasshopper.\"')\n",
    "    print('\"You have learned to perceive the invisible patterns of spiritual growth.\"')\n",
    "    print('\"The temple visitors\\'attle mysteries are revealed to your trained perception!\"')\n",
    "\n",
    "# Run the wisdom test\n",
    "test_your_wisdom(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌸 THE FOUR PATHS OF MASTERY: PROGRESSIVE EXTENSIONS\n",
    "\n",
    "Master Pai-Torch presents four paths to deepen your understanding of multi-variable multi-class classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension 1: Cook Oh-Pai-Timizer's Batch Feeding Wisdom\n",
    "*\"When cooking for many, efficiency and consistency matter most!\"*\n",
    "\n",
    "Cook Oh-Pai-Timizer bustles over, carrying a large pot of steaming soup. \"Ah, Grasshopper! I see you've learned to observe one visitor at a time, like preparing a single bowl of rice. But what happens when the entire monastery arrives for the evening meal? You must learn to process many visitors simultaneously—batch classification for efficient spiritual assessment!\"\n",
    "\n",
    "**NEW CONCEPTS:** Batch processing efficiency, mini-batch training, vectorized operations  \n",
    "**DIFFICULTY:** +15% (still Dan 1, but with batch optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🍜 EXTENSION 1: BATCH SPIRITUAL ASSESSMENT\n",
    "\n",
    "def train_with_batches(model, features, labels, batch_size=32, epochs=500, learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    Train the spiritual observer using mini-batches for efficiency.\n",
    "    \"\"\"\n",
    "    # TODO: Implement mini-batch training\n",
    "    # Hint: Use torch.utils.data.DataLoader or manually create batches\n",
    "    # Compare training time and final accuracy with full-batch training\n",
    "    pass\n",
    "\n",
    "def compare_batch_sizes():\n",
    "    \"\"\"\n",
    "    Compare training efficiency across different batch sizes.\n",
    "    \"\"\"\n",
    "    # TODO: Train models with batch_size=[1, 8, 32, 64, 300] (full batch)\n",
    "    # Measure training time and final accuracy for each\n",
    "    # Plot results showing Cook's wisdom about batch efficiency\n",
    "    pass\n",
    "\n",
    "# TRIAL: Train your model using different batch sizes\n",
    "# SUCCESS: Understand the trade-off between training speed and convergence stability\n",
    "# COOK'S WISDOM: \"The right batch size feeds many without burning the soup!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension 2: He-Ao-World's Measurement Mishaps\n",
    "*\"Oh dear! My old eyes mixed up some of the observation records...\"*\n",
    "\n",
    "He-Ao-World shuffles over, looking apologetic while holding a stack of observation scrolls. \"Grasshopper, I must confess... while copying Master Pai-Torch's visitor observations, these old hands made some errors. Some walking speeds got recorded in different units, some posture scores were written upside down, and I might have double-counted some breathing measurements. The data looks rather... inconsistent now.\"\n",
    "\n",
    "**NEW CONCEPTS:** Data preprocessing, feature normalization, handling inconsistent scales  \n",
    "**DIFFICULTY:** +25% (still Dan 1, but messier real-world data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧹 EXTENSION 2: CLEANING CORRUPTED OBSERVATIONS\n",
    "\n",
    "def corrupt_observations(features, corruption_level=0.3):\n",
    "    \"\"\"\n",
    "    Simulate He-Ao-World's data recording mistakes.\n",
    "    \"\"\"\n",
    "    # TODO: Randomly corrupt some features:\n",
    "    # - Scale some walking speeds by random factors (0.1x to 10x)\n",
    "    # - Flip some posture scores (1.0 - original_score)\n",
    "    # - Add random offsets to some question frequencies\n",
    "    # - Multiply some breathing depths by random values\n",
    "    pass\n",
    "\n",
    "def preprocess_features(corrupted_features):\n",
    "    \"\"\"\n",
    "    Clean and normalize the corrupted observation data.\n",
    "    \"\"\"\n",
    "    # TODO: Implement robust preprocessing:\n",
    "    # - Detect and handle outliers using statistical methods\n",
    "    # - Apply feature normalization (standardization or min-max scaling)\n",
    "    # - Store preprocessing parameters for consistent application\n",
    "    pass\n",
    "\n",
    "def compare_preprocessing_methods(original_features, corrupted_features, labels):\n",
    "    \"\"\"\n",
    "    Compare model performance with different preprocessing approaches.\n",
    "    \"\"\"\n",
    "    # TODO: Train models on:\n",
    "    # 1. Original clean data\n",
    "    # 2. Corrupted data (no preprocessing)\n",
    "    # 3. Corrupted data with standardization\n",
    "    # 4. Corrupted data with min-max scaling\n",
    "    # 5. Corrupted data with robust preprocessing (outlier handling)\n",
    "    pass\n",
    "\n",
    "# TRIAL: Handle He-Ao-World's data corruption gracefully\n",
    "# SUCCESS: Achieve similar accuracy to clean data through smart preprocessing\n",
    "# HE-AO'S WISDOM: \"Sometimes the messiest data teaches the most valuable lessons!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension 3: Master Ao-Tougrad's Confidence Mysteries\n",
    "*\"True wisdom lies not just in knowing the answer, but in knowing how certain you are...\"*\n",
    "\n",
    "Master Ao-Tougrad materializes from the shadows, speaking in their characteristically enigmatic way. \"Your model speaks in probabilities, but do you understand what these numbers truly mean? A prediction of 90% confidence carries different weight than one of 51%. Learn to interpret the uncertainty in your spiritual observations—some visitors reveal their nature clearly, others remain shrouded in mystery.\"\n",
    "\n",
    "**NEW CONCEPTS:** Prediction confidence analysis, uncertainty quantification, calibration  \n",
    "**DIFFICULTY:** +35% (still Dan 1, but deeper interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚡ EXTENSION 3: UNDERSTANDING PREDICTION CONFIDENCE\n",
    "\n",
    "def analyze_prediction_confidence(model, features, labels):\n",
    "    \"\"\"\n",
    "    Analyze how confident the model is in its predictions.\n",
    "    \"\"\"\n",
    "    # TODO: Calculate confidence metrics:\n",
    "    # - Maximum probability for each prediction\n",
    "    # - Entropy of probability distributions\n",
    "    # - Difference between top two probabilities\n",
    "    # Group predictions by confidence level and analyze accuracy\n",
    "    pass\n",
    "\n",
    "def create_confidence_visualization(model, features, labels):\n",
    "    \"\"\"\n",
    "    Visualize the relationship between confidence and accuracy.\n",
    "    \"\"\"\n",
    "    # TODO: Create plots showing:\n",
    "    # - Confidence distribution for correct vs incorrect predictions\n",
    "    # - Accuracy vs confidence bins\n",
    "    # - Feature patterns that lead to high/low confidence\n",
    "    pass\n",
    "\n",
    "def implement_rejection_option(model, features, labels, confidence_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Implement a rejection option: refuse to classify when confidence is too low.\n",
    "    \"\"\"\n",
    "    # TODO: \n",
    "    # - Calculate prediction confidences\n",
    "    # - Only make predictions above threshold\n",
    "    # - Analyze the trade-off between coverage and accuracy\n",
    "    # - Find optimal threshold that maximizes reliable predictions\n",
    "    pass\n",
    "\n",
    "# TRIAL: Understand when your model is uncertain and why\n",
    "# SUCCESS: Identify the confidence threshold that gives 95%+ accuracy on accepted predictions\n",
    "# AO-TOUGRAD'S WISDOM: \"The wise classifier knows when to say 'I do not know.'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension 4: Suki's Advanced Behavioral Patterns\n",
    "*\"Meow meow purr.\" (Translation: \"Your features are primitive, human. Observe deeper patterns.\")*\n",
    "\n",
    "Suki sits regally beside Master Pai-Torch, tail swishing with what appears to be mild disapproval. Master Pai-Torch translates her mystical communications: \"The sacred cat observes that you process each behavioral feature independently, like counting fish without noticing the pattern of the school. True spiritual insight comes from understanding how behaviors interact—perhaps walking speed and posture combine in ways more subtle than mere addition.\"\n",
    "\n",
    "**NEW CONCEPTS:** Feature interactions, polynomial features, feature engineering  \n",
    "**DIFFICULTY:** +45% (still Dan 1, but advanced feature understanding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🐱 EXTENSION 4: SUKI'S FEATURE INTERACTION WISDOM\n",
    "\n",
    "def create_interaction_features(features):\n",
    "    \"\"\"\n",
    "    Create new features based on interactions between original behaviors.\n",
    "    \"\"\"\n",
    "    # TODO: Engineer meaningful feature interactions:\n",
    "    # - walking_speed * posture_score (coordination index)\n",
    "    # - question_frequency / breathing_depth (anxiety ratio)\n",
    "    # - walking_speed / breathing_depth (urgency factor)\n",
    "    # - posture_score * breathing_depth (mindfulness indicator)\n",
    "    # Return expanded feature tensor\n",
    "    pass\n",
    "\n",
    "def create_polynomial_features(features, degree=2):\n",
    "    \"\"\"\n",
    "    Create polynomial feature combinations up to specified degree.\n",
    "    \"\"\"\n",
    "    # TODO: Generate polynomial features:\n",
    "    # - Degree 1: original features\n",
    "    # - Degree 2: all pairwise products, squares\n",
    "    # - Be careful about feature explosion!\n",
    "    pass\n",
    "\n",
    "def analyze_feature_importance(model, original_features, enhanced_features, labels):\n",
    "    \"\"\"\n",
    "    Compare model performance and feature importance with enhanced features.\n",
    "    \"\"\"\n",
    "    # TODO: Train models with:\n",
    "    # 1. Original 4 features\n",
    "    # 2. Original + hand-crafted interactions\n",
    "    # 3. Original + polynomial features\n",
    "    # \n",
    "    # Analyze which new features are most useful\n",
    "    # Visualize decision boundaries in 2D projections\n",
    "    pass\n",
    "\n",
    "def visualize_interaction_effects(features, labels):\n",
    "    \"\"\"\n",
    "    Create visualizations showing how feature interactions reveal spiritual stages.\n",
    "    \"\"\"\n",
    "    # TODO: Create scatter plots of feature pairs colored by class\n",
    "    # Show how combinations like (walking_speed, posture_score) \n",
    "    # separate classes better than individual features\n",
    "    pass\n",
    "\n",
    "# TRIAL: Discover which behavioral combinations most clearly reveal spiritual development\n",
    "# SUCCESS: Achieve higher accuracy using intelligently engineered features\n",
    "# MASTERY: Understand why certain feature interactions matter for spiritual classification\n",
    "# SUKI'S WISDOM: \"Purr meow purr.\" (\"Behaviors dance together, human. Learn the choreography.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔥 CORRECTING YOUR FORM: A STANCE IMBALANCE\n",
    "\n",
    "Master Pai-Torch observes your classification ritual with a keen eye. \"Your eager mind grasps the patterns well, Grasshopper, but I detect instability in your training stance. See how your gradient flow wavers?\"\n",
    "\n",
    "A previous disciple left this flawed multi-class training ritual. The form has become unsteady—can you restore proper technique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔥 CORRECTING YOUR FORM: A STANCE IMBALANCE\n",
    "\n",
    "def unstable_classification_training(model, features, labels, epochs=1000):\n",
    "    \"\"\"This multi-class training stance has lost its balance - your form needs correction! 🥋\"\"\"\n",
    "    \n",
    "    # Using the wrong loss function for multi-class classification\n",
    "    criterion = nn.MSELoss()  # This is for regression, not classification!\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        raw_scores = model(features)\n",
    "        \n",
    "        # Converting labels to one-hot for MSE (unnecessary and problematic)\n",
    "        one_hot_labels = torch.zeros(labels.size(0), 3)\n",
    "        one_hot_labels.scatter_(1, labels.unsqueeze(1), 1)\n",
    "        \n",
    "        loss = criterion(raw_scores, one_hot_labels)\n",
    "        \n",
    "        # Backward pass - but missing something critical!\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # The Gradient Spirits are not being properly dismissed!\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}: Loss = {loss.item():.4f}')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# DEBUGGING CHALLENGE: This training ritual has THREE critical errors!\n",
    "# ERROR 1: Wrong loss function - MSE is for regression, not multi-class classification\n",
    "# ERROR 2: Unnecessary one-hot encoding - CrossEntropyLoss expects class indices\n",
    "# ERROR 3: Missing optimizer.zero_grad() - gradients accumulate without proper clearing\n",
    "#\n",
    "# MASTER'S WISDOM: \"The untrained mind applies tools without understanding their purpose.\n",
    "#                   Each loss function serves its sacred duty—regression seeks closeness,\n",
    "#                   classification seeks probability. Know the difference, and choose wisely.\"\n",
    "#\n",
    "# HINT: The correct form uses CrossEntropyLoss with raw class indices, \n",
    "#       and always clears gradients before each backward pass.\n",
    "\n",
    "print(\"🥋 Master Pai-Torch challenges you to identify and correct the three errors in this training ritual.\")\n",
    "print(\"   Can you restore proper multi-class classification form?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}