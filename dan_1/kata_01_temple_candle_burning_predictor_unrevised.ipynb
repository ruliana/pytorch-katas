{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ruliana/pytorch-katas/blob/main/dan_1/kata_01_temple_candle_burning_predictor_unrevised.ipynb)\n",
    "\n",
    "## üèÆ The Ancient Scroll Unfurls üèÆ\n",
    "\n",
    "**THE FORBIDDEN CANDLE FLAME PROPHECY**\n",
    "\n",
    "Dan Level: 1 (Temple Sweeper) | Time: 45 minutes | Sacred Arts: Linear Regression, Gradient Descent, Training Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìú THE CHALLENGE\n",
    "\n",
    "The temple grows darker as winter approaches. Master Pai-Torch summons you to the candlemaking chamber, where hundreds of sacred candles line the walls in perfect rows. The ancient master's eyes gleam with an otherworldly light as they speak in hushed tones.\n",
    "\n",
    "\"Grasshopper, you have swept floors and fed cats, but now you must learn the **Forbidden Knowledge** - the art of predicting flame duration. This sacred technique has been passed down through generations of temple keepers, but beware...\" Master Pai-Torch's voice drops to a whisper. \"The spirits of gradient descent are powerful but dangerous. Handle them carelessly, and they will either vanish into nothingness or explode beyond control.\"\n",
    "\n",
    "From the shadows, Master Ao-Tougrad emerges silently, leaving a cryptic note on the table: *\"The path backward reveals the way forward. Zero the spirits before each journey, lest they accumulate old wisdom.\"*\n",
    "\n",
    "Master Pai-Torch nods gravely. \"The temple candles are made with different amounts of sacred wax. The ancient scrolls speak of a mystical relationship: a candle's burning time depends on its weight. But this knowledge comes with great responsibility. You must learn to tame the gradient spirits through careful ritual, or your training will fail spectacularly.\"\n",
    "\n",
    "The master gestures to a collection of candles. \"Each candle's weight determines how long it burns. The temple records show that heavier candles burn longer, but the exact relationship has been lost to time. You must discover this sacred formula and use it to predict how long any candle will burn. But remember - this is **Forbidden Knowledge** that must be mastered safely under strict supervision.\"\n",
    "\n",
    "### üéØ THE SACRED OBJECTIVES\n",
    "\n",
    "- [ ] Master the forbidden art of gradient descent without exploding or vanishing spirits\n",
    "- [ ] Discover the mystical relationship between candle weight and burning time\n",
    "- [ ] Create a prophecy system that can predict any candle's burning duration\n",
    "- [ ] Demonstrate proper gradient spirit management in your training ritual\n",
    "- [ ] Achieve Master Pai-Torch's strict accuracy requirements (loss < 25)\n",
    "- [ ] Understand why this knowledge was considered \"forbidden\" (debugging challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üïØÔ∏è THE SACRED CANDLE DATA GENERATION SCROLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "# Set the sacred seed for reproducible mystical results\n",
    "torch.manual_seed(42)\n",
    "\n",
    "def generate_candle_burning_data(n_candles: int = 100, chaos_level: float = 0.15,\n",
    "                                sacred_seed: int = 42) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Generate observations of temple candle burning patterns.\n",
    "    \n",
    "    Ancient temple wisdom reveals: burning_time = 3.2 * weight + 15\n",
    "    Where weight is in sacred units (grams) and time is in minutes.\n",
    "    \n",
    "    Args:\n",
    "        n_candles: Number of candle observations to generate\n",
    "        chaos_level: Amount of flame unpredictability (0.0 = perfect formula, 1.0 = pure chaos)\n",
    "        sacred_seed: Ensures consistent mystical randomness\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (candle_weights, burning_times) as sacred tensors\n",
    "    \"\"\"\n",
    "    torch.manual_seed(sacred_seed)\n",
    "    \n",
    "    # Temple candles range from 10g to 50g (sacred measurements)\n",
    "    candle_weights = torch.rand(n_candles, 1) * 40 + 10\n",
    "    \n",
    "    # The sacred formula known to ancient candlemakers\n",
    "    base_time = 15  # Even an empty candle holder burns for 15 minutes\n",
    "    time_per_gram = 3.2  # Each gram of wax burns for 3.2 minutes\n",
    "    \n",
    "    burning_times = time_per_gram * candle_weights.squeeze() + base_time\n",
    "    \n",
    "    # Add flame chaos (wind, humidity, spiritual energy fluctuations)\n",
    "    chaos = torch.randn(n_candles) * chaos_level * burning_times.std()\n",
    "    burning_times = burning_times + chaos\n",
    "    \n",
    "    # Even mystical flames have physical limits\n",
    "    burning_times = torch.clamp(burning_times, 5, 300)  # 5 min to 5 hours maximum\n",
    "    \n",
    "    return candle_weights, burning_times.unsqueeze(1)\n",
    "\n",
    "def visualize_candle_mysteries(weights: torch.Tensor, times: torch.Tensor,\n",
    "                              predictions: torch.Tensor = None):\n",
    "    \"\"\"Display the sacred patterns of temple candle burning.\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(weights.numpy(), times.numpy(), alpha=0.6, color='orange',\n",
    "                s=60, label='Sacred Candle Observations')\n",
    "    \n",
    "    if predictions is not None:\n",
    "        # Sort for a clean prediction line\n",
    "        sorted_indices = torch.argsort(weights.squeeze())\n",
    "        sorted_weights = weights[sorted_indices]\n",
    "        sorted_predictions = predictions[sorted_indices]\n",
    "        plt.plot(sorted_weights.numpy(), sorted_predictions.detach().numpy(),\n",
    "                'red', linewidth=3, label='Your Mystical Predictions')\n",
    "    \n",
    "    plt.xlabel('Candle Weight (Sacred Grams)')\n",
    "    plt.ylabel('Burning Time (Minutes)')\n",
    "    plt.title('üïØÔ∏è The Mysteries of Temple Candle Burning üïØÔ∏è')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Generate your training data\n",
    "candle_weights, burning_times = generate_candle_burning_data(n_candles=80, chaos_level=0.12)\n",
    "\n",
    "print(\"üïØÔ∏è Master Pai-Torch has prepared the sacred candle data...\")\n",
    "print(f\"Training on {len(candle_weights)} candle observations\")\n",
    "print(f\"Weight range: {candle_weights.min().item():.1f}g to {candle_weights.max().item():.1f}g\")\n",
    "print(f\"Burning time range: {burning_times.min().item():.1f} to {burning_times.max().item():.1f} minutes\")\n",
    "\n",
    "# Visualize the mysterious data\n",
    "visualize_candle_mysteries(candle_weights, burning_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî• FIRST MOVEMENTS: THE FORBIDDEN KNOWLEDGE TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CandleBurningPredictor(nn.Module):\n",
    "    \"\"\"A mystical artifact for predicting sacred candle burning times.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_features: int = 1):\n",
    "        super(CandleBurningPredictor, self).__init__()\n",
    "        # TODO: Create the Linear layer that transforms weight to burning time\n",
    "        # Hint: torch.nn.Linear(input_size, output_size) is the sacred transformation\n",
    "        # Remember: input is candle weight, output is burning time\n",
    "        self.linear = None\n",
    "        \n",
    "    def forward(self, features: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Channel the forbidden knowledge through the mystical network.\"\"\"\n",
    "        # TODO: Pass the input through your Linear layer\n",
    "        # Warning: This is where the forbidden knowledge flows!\n",
    "        return None\n",
    "\n",
    "def forbidden_training_ritual(model: nn.Module, features: torch.Tensor, target: torch.Tensor,\n",
    "                             epochs: int = 1000, learning_rate: float = 0.01) -> list:\n",
    "    \"\"\"\n",
    "    The forbidden training ritual - handle the gradient spirits with extreme care!\n",
    "    \n",
    "    Args:\n",
    "        model: Your mystical prediction artifact\n",
    "        features: Candle weights (input)\n",
    "        target: Burning times (what we want to predict)\n",
    "        epochs: Number of training cycles\n",
    "        learning_rate: How boldly to step in the gradient realm\n",
    "        \n",
    "    Returns:\n",
    "        List of loss values during the forbidden ritual\n",
    "    \"\"\"\n",
    "    # TODO: Choose your loss calculation method\n",
    "    # Hint: Mean Squared Error (MSELoss) is favored for continuous predictions\n",
    "    criterion = None\n",
    "    \n",
    "    # TODO: Choose your gradient descent optimizer\n",
    "    # Hint: SGD (Stochastic Gradient Descent) is the traditional forbidden path\n",
    "    optimizer = None\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    print(\"üö® DANGER: Beginning the forbidden gradient descent ritual...\")\n",
    "    print(\"Master Pai-Torch watches carefully for gradient explosions...\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # TODO: CRITICAL - Clear the gradient spirits from previous cycle\n",
    "        # Hint: optimizer.zero_grad() banishes accumulated gradient spirits\n",
    "        # WARNING: Forget this step and the spirits will accumulate dangerously!\n",
    "        \n",
    "        # TODO: Forward pass - channel the forbidden knowledge\n",
    "        predictions = None\n",
    "        \n",
    "        # TODO: Compute the sacred loss\n",
    "        loss = None\n",
    "        \n",
    "        # TODO: Backward pass - summon the gradient spirits\n",
    "        # Hint: loss.backward() calls upon the spirits of backpropagation\n",
    "        \n",
    "        # TODO: Update the sacred parameters\n",
    "        # Hint: optimizer.step() commands the spirits to update your model\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # Master Pai-Torch's watchful progress reports\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Forbidden Loss: {loss.item():.4f}')\n",
    "            if loss.item() < 50:\n",
    "                print(\"‚ö° The gradient spirits grow calmer...\")\n",
    "            if loss.item() < 25:\n",
    "                print(\"‚ú® Master Pai-Torch nods with approval!\")\n",
    "                \n",
    "    print(\"\\nüéâ The forbidden ritual is complete!\")\n",
    "    return losses\n",
    "\n",
    "# Initialize your mystical predictor\n",
    "model = CandleBurningPredictor(input_features=1)\n",
    "\n",
    "print(\"üîÆ Master Pai-Torch has prepared your mystical artifact...\")\n",
    "print(f\"Model architecture: {model}\")\n",
    "print(\"\\n‚ö†Ô∏è  Remember: This is FORBIDDEN KNOWLEDGE. Handle with extreme care!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° THE TRIALS OF MASTERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your model with the forbidden knowledge\n",
    "loss_history = forbidden_training_ritual(model, candle_weights, burning_times, \n",
    "                                        epochs=1000, learning_rate=0.001)\n",
    "\n",
    "# Test your mystical predictions\n",
    "with torch.no_grad():\n",
    "    predictions = model(candle_weights)\n",
    "    \n",
    "# Visualize your mastery\n",
    "visualize_candle_mysteries(candle_weights, burning_times, predictions)\n",
    "\n",
    "# Plot the forbidden knowledge learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_history, color='red', linewidth=2)\n",
    "plt.title('üî• The Forbidden Knowledge Learning Curve üî•')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Sacred Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 1: Basic Mastery Requirements\n",
    "- [ ] Loss decreases consistently (no rogue gradient spirits)\n",
    "- [ ] Final loss below 25 (Master Pai-Torch's strict threshold)\n",
    "- [ ] Model weight approximately 3.2 (¬±0.5), bias around 15 (¬±3)\n",
    "- [ ] Predictions form a clean line through the scattered candle data\n",
    "\n",
    "### Trial 2: Understanding Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_your_forbidden_wisdom(model):\n",
    "    \"\"\"Master Pai-Torch's evaluation of your forbidden knowledge mastery.\"\"\"\n",
    "    print(\"üîç Master Pai-Torch examines your forbidden knowledge...\")\n",
    "    \n",
    "    # Test correct tensor shapes\n",
    "    test_weights = torch.tensor([[20.0], [30.0], [40.0]])\n",
    "    predictions = model(test_weights)\n",
    "    assert predictions.shape == (3, 1), f\"Shape mismatch! Expected (3, 1), got {predictions.shape}\"\n",
    "    \n",
    "    # Test the forbidden parameters\n",
    "    weight = model.linear.weight.item()\n",
    "    bias = model.linear.bias.item()\n",
    "    \n",
    "    print(f\"üìä Your mystical parameters:\")\n",
    "    print(f\"   Weight (time per gram): {weight:.2f}\")\n",
    "    print(f\"   Bias (base burning time): {bias:.2f}\")\n",
    "    \n",
    "    # Validate against the sacred formula\n",
    "    assert 2.7 <= weight <= 3.7, f\"Weight {weight:.2f} deviates from the sacred formula (should be ~3.2)!\"\n",
    "    assert 12 <= bias <= 18, f\"Bias {bias:.2f} - even empty candle holders burn for ~15 minutes!\"\n",
    "    \n",
    "    # Test realistic predictions\n",
    "    light_candle = torch.tensor([[15.0]])  # 15g candle\n",
    "    heavy_candle = torch.tensor([[45.0]])  # 45g candle\n",
    "    \n",
    "    light_time = model(light_candle).item()\n",
    "    heavy_time = model(heavy_candle).item()\n",
    "    \n",
    "    print(f\"\\nüïØÔ∏è Mystical predictions:\")\n",
    "    print(f\"   15g candle: {light_time:.1f} minutes\")\n",
    "    print(f\"   45g candle: {heavy_time:.1f} minutes\")\n",
    "    \n",
    "    assert heavy_time > light_time, \"Heavy candles must burn longer than light ones!\"\n",
    "    assert 60 <= light_time <= 80, f\"15g candle time {light_time:.1f}min seems unrealistic!\"\n",
    "    assert 140 <= heavy_time <= 170, f\"45g candle time {heavy_time:.1f}min seems unrealistic!\"\n",
    "    \n",
    "    print(\"\\n‚ú® Master Pai-Torch's eyes gleam with approval!\")\n",
    "    print(\"üéâ You have successfully mastered the forbidden knowledge!\")\n",
    "    print(\"\\nüí´ 'The gradient spirits bow to your disciplined ritual, Grasshopper.'\")\n",
    "\n",
    "# Test your mastery\n",
    "test_your_forbidden_wisdom(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üå∏ THE FOUR PATHS OF MASTERY: PROGRESSIVE EXTENSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension 1: He-Ao-World's Clumsy Candle Mix-up\n",
    "*\"Oh! So sorry! These old hands knocked over the candle storage...\"*\n",
    "\n",
    "He-Ao-World shuffles into the chamber, looking apologetic while cleaning up scattered candles.\n",
    "\n",
    "\"I was organizing the sacred candles by weight when I accidentally mixed up the measurements! Some candles are labeled in ounces instead of grams, and I think I double-counted some weights. The data looks... well, quite chaotic now. Master Pai-Torch says this is actually excellent training for real-world conditions!\"\n",
    "\n",
    "**NEW CONCEPTS:** Data preprocessing, outlier detection, robust training  \n",
    "**DIFFICULTY:** +15% (still Dan 1, but messier data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_messy_candle_data(clean_weights: torch.Tensor, clean_times: torch.Tensor, \n",
    "                           corruption_rate: float = 0.2) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    He-Ao-World's accidental data corruption simulation.\n",
    "    \n",
    "    Args:\n",
    "        clean_weights: Original candle weights\n",
    "        clean_times: Original burning times\n",
    "        corruption_rate: Fraction of data to corrupt\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (corrupted_weights, corrupted_times)\n",
    "    \"\"\"\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    messy_weights = clean_weights.clone()\n",
    "    messy_times = clean_times.clone()\n",
    "    \n",
    "    n_corrupt = int(len(messy_weights) * corruption_rate)\n",
    "    corrupt_indices = torch.randperm(len(messy_weights))[:n_corrupt]\n",
    "    \n",
    "    # He-Ao-World's \"accidents\"\n",
    "    for idx in corrupt_indices:\n",
    "        accident_type = torch.randint(0, 3, (1,)).item()\n",
    "        \n",
    "        if accident_type == 0:  # Ounces instead of grams\n",
    "            messy_weights[idx] = messy_weights[idx] * 28.35  # Convert to ounces\n",
    "        elif accident_type == 1:  # Double-counted weight\n",
    "            messy_weights[idx] = messy_weights[idx] * 2\n",
    "        else:  # Completely wrong measurement\n",
    "            messy_weights[idx] = torch.rand(1) * 200 + 100  # Random large value\n",
    "    \n",
    "    return messy_weights, messy_times\n",
    "\n",
    "def detect_and_clean_outliers(weights: torch.Tensor, times: torch.Tensor, \n",
    "                             z_threshold: float = 3.0) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Clean He-Ao-World's accidental data corruption.\n",
    "    \n",
    "    TODO: Implement outlier detection and removal\n",
    "    Hint: Use z-score to identify outliers (|z| > z_threshold)\n",
    "    Hint: z_score = (value - mean) / std\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (cleaned_weights, cleaned_times)\n",
    "    \"\"\"\n",
    "    # TODO: Calculate z-scores for weights\n",
    "    # TODO: Identify outliers using z_threshold\n",
    "    # TODO: Return only the clean data points\n",
    "    pass\n",
    "\n",
    "# Create He-Ao-World's messy data\n",
    "messy_weights, messy_times = create_messy_candle_data(candle_weights, burning_times)\n",
    "\n",
    "print(\"üßπ He-Ao-World's data corruption:\")\n",
    "print(f\"Original weight range: {candle_weights.min().item():.1f}g to {candle_weights.max().item():.1f}g\")\n",
    "print(f\"Messy weight range: {messy_weights.min().item():.1f}g to {messy_weights.max().item():.1f}g\")\n",
    "\n",
    "# Visualize the chaos\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(candle_weights.numpy(), burning_times.numpy(), alpha=0.6, color='orange')\n",
    "plt.title('Original Clean Data')\n",
    "plt.xlabel('Weight (g)')\n",
    "plt.ylabel('Burning Time (min)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(messy_weights.numpy(), messy_times.numpy(), alpha=0.6, color='red')\n",
    "plt.title('He-Ao-World\\'s Messy Data')\n",
    "plt.xlabel('Weight (g)')\n",
    "plt.ylabel('Burning Time (min)')\n",
    "plt.show()\n",
    "\n",
    "# TRIAL: Clean the data and train a robust model\n",
    "# SUCCESS: Achieve similar performance to the clean data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension 2: Master Ao-Tougrad's Gradient Wisdom\n",
    "*\"The spirits whisper secrets of momentum and adaptive learning...\"*\n",
    "\n",
    "Master Ao-Tougrad emerges from the shadows, leaving a mysterious note on your training altar:\n",
    "\n",
    "*\"Young seeker of forbidden knowledge, your basic ritual succeeds, but the gradient spirits grow restless with repetitive steps. Ancient wisdom speaks of momentum - let each step remember the previous journey. And beware: not all learning rates serve all spirits equally.\"*\n",
    "\n",
    "**NEW CONCEPTS:** Momentum optimization, learning rate scheduling, advanced optimizers  \n",
    "**DIFFICULTY:** +25% (still Dan 1, but smarter optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_gradient_ritual(model: nn.Module, features: torch.Tensor, target: torch.Tensor,\n",
    "                           epochs: int = 1000, learning_rate: float = 0.01, \n",
    "                           momentum: float = 0.9) -> Tuple[list, list]:\n",
    "    \"\"\"\n",
    "    Master Ao-Tougrad's advanced gradient descent ritual.\n",
    "    \n",
    "    Args:\n",
    "        momentum: How much to remember from previous gradient steps\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (loss_history, learning_rate_history)\n",
    "    \"\"\"\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # TODO: Use SGD with momentum instead of basic SGD\n",
    "    # Hint: torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    optimizer = None\n",
    "    \n",
    "    # TODO: Create a learning rate scheduler\n",
    "    # Hint: torch.optim.lr_scheduler.StepLR(optimizer, step_size=300, gamma=0.5)\n",
    "    # This reduces learning rate by half every 300 epochs\n",
    "    scheduler = None\n",
    "    \n",
    "    losses = []\n",
    "    learning_rates = []\n",
    "    \n",
    "    print(\"üåä Master Ao-Tougrad's advanced ritual begins...\")\n",
    "    print(f\"Initial learning rate: {learning_rate}, Momentum: {momentum}\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(features)\n",
    "        loss = criterion(predictions, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # TODO: Step the learning rate scheduler\n",
    "        # Hint: scheduler.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        learning_rates.append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        if (epoch + 1) % 200 == 0:\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, LR: {current_lr:.6f}')\n",
    "    \n",
    "    return losses, learning_rates\n",
    "\n",
    "# Create a fresh model for comparison\n",
    "advanced_model = CandleBurningPredictor(input_features=1)\n",
    "\n",
    "# TODO: Train with advanced optimization\n",
    "# TODO: Compare convergence speed with basic SGD\n",
    "# TODO: Visualize learning rate decay over time\n",
    "\n",
    "# TRIAL: Compare basic SGD vs momentum SGD with scheduling\n",
    "# SUCCESS: Achieve faster convergence and more stable training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension 3: Master Pai-Torch's Batch Wisdom\n",
    "*\"The wise student learns from many candles at once, not one by one.\"*\n",
    "\n",
    "Master Pai-Torch sits in contemplative silence, then speaks:\n",
    "\n",
    "\"Grasshopper, you have learned to predict one candle at a time, but the temple holds thousands. The ancient art of batch learning allows the gradient spirits to learn from multiple candles simultaneously. This is more efficient, but requires understanding how to manage mini-batches of sacred data.\"\n",
    "\n",
    "**NEW CONCEPTS:** Mini-batch training, DataLoader, batch processing  \n",
    "**DIFFICULTY:** +35% (still Dan 1, but with batch processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def create_batch_training_data(n_candles: int = 500) -> Tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"\n",
    "    Create larger dataset with train/validation split for batch training.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (train_loader, val_loader)\n",
    "    \"\"\"\n",
    "    # Generate more candle data\n",
    "    all_weights, all_times = generate_candle_burning_data(n_candles=n_candles, chaos_level=0.1)\n",
    "    \n",
    "    # Split into train/validation (80/20)\n",
    "    split_idx = int(0.8 * len(all_weights))\n",
    "    \n",
    "    train_weights = all_weights[:split_idx]\n",
    "    train_times = all_times[:split_idx]\n",
    "    val_weights = all_weights[split_idx:]\n",
    "    val_times = all_times[split_idx:]\n",
    "    \n",
    "    # TODO: Create TensorDataset for train and validation\n",
    "    # Hint: TensorDataset(features, targets)\n",
    "    train_dataset = None\n",
    "    val_dataset = None\n",
    "    \n",
    "    # TODO: Create DataLoader for batch processing\n",
    "    # Hint: DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    train_loader = None\n",
    "    val_loader = None\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "def batch_training_ritual(model: nn.Module, train_loader: DataLoader, val_loader: DataLoader,\n",
    "                         epochs: int = 50) -> Tuple[list, list]:\n",
    "    \"\"\"\n",
    "    Master Pai-Torch's batch training ritual.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (train_losses, val_losses)\n",
    "    \"\"\"\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    print(\"üèÆ Master Pai-Torch's batch wisdom ritual begins...\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        \n",
    "        # TODO: Iterate through batches in train_loader\n",
    "        # Hint: for batch_weights, batch_times in train_loader:\n",
    "        #           # Standard training loop for each batch\n",
    "        \n",
    "        # TODO: Calculate average training loss for the epoch\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # TODO: Iterate through validation batches\n",
    "            # TODO: Calculate validation loss (no gradients needed)\n",
    "            pass\n",
    "        \n",
    "        # TODO: Store average losses\n",
    "        # TODO: Print progress every 10 epochs\n",
    "        \n",
    "    return train_losses, val_losses\n",
    "\n",
    "# Create batch training data\n",
    "train_loader, val_loader = create_batch_training_data(n_candles=500)\n",
    "\n",
    "# Create fresh model for batch training\n",
    "batch_model = CandleBurningPredictor(input_features=1)\n",
    "\n",
    "# TODO: Train with batch processing\n",
    "# TODO: Compare single-batch vs mini-batch training\n",
    "# TODO: Visualize train/validation loss curves\n",
    "\n",
    "# TRIAL: Train on 500 candles using mini-batches\n",
    "# SUCCESS: Achieve stable training with validation monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension 4: The Complete Candle Mastery Challenge\n",
    "*\"True mastery combines all forbidden knowledge into one supreme technique.\"*\n",
    "\n",
    "Master Pai-Torch and Master Ao-Tougrad stand together, their combined presence filling the chamber with mystical energy.\n",
    "\n",
    "\"Grasshopper,\" Master Pai-Torch intones, \"you have learned the individual arts - basic training, data cleaning, advanced optimization, and batch processing. But the ultimate test requires combining all forbidden knowledge into one supreme candle prediction system.\"\n",
    "\n",
    "Master Ao-Tougrad nods silently, leaving a final cryptic note: *\"The master's path integrates all lessons. Clean data, wise optimization, efficient batching, and robust validation - united as one.\"*\n",
    "\n",
    "**NEW CONCEPTS:** Model pipeline, end-to-end training, evaluation metrics  \n",
    "**DIFFICULTY:** +45% (still Dan 1, but complete system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MasterCandlePredictor:\n",
    "    \"\"\"\n",
    "    The ultimate candle prediction system combining all forbidden knowledge.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_features: int = 1):\n",
    "        self.model = CandleBurningPredictor(input_features)\n",
    "        self.training_history = {}\n",
    "        self.is_trained = False\n",
    "        \n",
    "    def clean_data(self, weights: torch.Tensor, times: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Apply He-Ao-World's data cleaning wisdom.\n",
    "        \n",
    "        TODO: Implement comprehensive data cleaning:\n",
    "        - Remove outliers using z-score\n",
    "        - Validate data ranges\n",
    "        - Report cleaning statistics\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def train_master_system(self, weights: torch.Tensor, times: torch.Tensor,\n",
    "                          epochs: int = 100, batch_size: int = 32,\n",
    "                          learning_rate: float = 0.001, momentum: float = 0.9,\n",
    "                          validation_split: float = 0.2) -> dict:\n",
    "        \"\"\"\n",
    "        The complete training ritual combining all forbidden knowledge.\n",
    "        \n",
    "        TODO: Implement the complete training pipeline:\n",
    "        1. Clean the input data\n",
    "        2. Create train/validation split\n",
    "        3. Set up DataLoaders with proper batch size\n",
    "        4. Use Adam optimizer with learning rate scheduling\n",
    "        5. Train with both training and validation monitoring\n",
    "        6. Return comprehensive training history\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with training metrics and history\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def evaluate_predictions(self, test_weights: torch.Tensor, test_times: torch.Tensor) -> dict:\n",
    "        \"\"\"\n",
    "        Comprehensive evaluation of the master system.\n",
    "        \n",
    "        TODO: Calculate multiple evaluation metrics:\n",
    "        - Mean Squared Error\n",
    "        - Mean Absolute Error\n",
    "        - R¬≤ Score\n",
    "        - Prediction accuracy within tolerance\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with evaluation metrics\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def predict_candle_burning(self, weight: float) -> dict:\n",
    "        \"\"\"\n",
    "        Make a single candle prediction with confidence information.\n",
    "        \n",
    "        Args:\n",
    "            weight: Candle weight in grams\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with prediction and confidence info\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Master system must be trained first!\")\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            weight_tensor = torch.tensor([[weight]])\n",
    "            prediction = self.model(weight_tensor).item()\n",
    "            \n",
    "        return {\n",
    "            'candle_weight': weight,\n",
    "            'predicted_burning_time': prediction,\n",
    "            'confidence': 'high' if 10 <= weight <= 50 else 'low'\n",
    "        }\n",
    "\n",
    "# Create the master system\n",
    "master_system = MasterCandlePredictor()\n",
    "\n",
    "# Generate comprehensive test data\n",
    "test_weights, test_times = generate_candle_burning_data(n_candles=1000, chaos_level=0.15)\n",
    "\n",
    "# Add some of He-Ao-World's \"accidents\"\n",
    "messy_weights, messy_times = create_messy_candle_data(test_weights, test_times, corruption_rate=0.1)\n",
    "\n",
    "print(\"üéØ THE ULTIMATE CANDLE MASTERY CHALLENGE\")\n",
    "print(\"================================================\")\n",
    "print(f\"Training data: {len(messy_weights)} candles (with 10% He-Ao-World corruption)\")\n",
    "print(\"\\nChallenges to overcome:\")\n",
    "print(\"‚úì Clean corrupted data\")\n",
    "print(\"‚úì Implement robust batch training\")\n",
    "print(\"‚úì Use advanced optimization\")\n",
    "print(\"‚úì Monitor validation performance\")\n",
    "print(\"‚úì Provide comprehensive evaluation\")\n",
    "\n",
    "# ULTIMATE TRIAL: Build and train the complete system\n",
    "# SUCCESS CRITERIA:\n",
    "# - Clean data effectively (remove outliers)\n",
    "# - Train with <20 MSE loss on validation\n",
    "# - Achieve >0.95 R¬≤ score on test data\n",
    "# - Provide accurate single-candle predictions\n",
    "# - Generate comprehensive training reports\n",
    "\n",
    "# TODO: Implement and train the master system\n",
    "# TODO: Evaluate on clean test data\n",
    "# TODO: Test individual candle predictions\n",
    "# TODO: Generate final mastery report\n",
    "\n",
    "print(\"\\nüåü Master Pai-Torch awaits your complete implementation...\")\n",
    "print(\"üí´ 'True mastery integrates all forbidden knowledge, Grasshopper.'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî• CORRECTING YOUR FORM: A STANCE IMBALANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Master Pai-Torch observes your training ritual with growing concern. The ancient master's eyes narrow as they watch your gradient flows.\n",
    "\n",
    "\"Grasshopper, I see why this knowledge was forbidden! Your eager mind races ahead of your disciplined form. Observe how this previous student's ritual has become corrupted - the gradient spirits accumulate and grow wild!\"\n",
    "\n",
    "A previous disciple left this flawed training code. The forbidden knowledge has become dangerous - can you identify and correct the critical errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupted_forbidden_ritual(model: nn.Module, features: torch.Tensor, target: torch.Tensor,\n",
    "                              epochs: int = 500, learning_rate: float = 0.01):\n",
    "    \"\"\"\n",
    "    üö® DANGER: This ritual has lost its balance - the gradient spirits run wild!\n",
    "    \n",
    "    The previous student's training has become corrupted. Can you spot the critical errors\n",
    "    that make this forbidden knowledge truly dangerous?\n",
    "    \"\"\"\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    print(\"üî• Beginning the corrupted ritual...\")\n",
    "    print(\"‚ö†Ô∏è  Warning: The gradient spirits grow restless!\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass through the forbidden knowledge\n",
    "        predictions = model(features)\n",
    "        loss = criterion(predictions, target)\n",
    "        \n",
    "        # Summon the gradient spirits\n",
    "        loss.backward()\n",
    "        \n",
    "        # Command the spirits to update the sacred parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Report to Master Pai-Torch\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}: Loss = {loss.item():.4f}')\n",
    "            if loss.item() > 1000:\n",
    "                print(\"üí• THE GRADIENT SPIRITS EXPLODE WITH RAGE!\")\n",
    "                print(\"üö® Master Pai-Torch rushes to contain the spiritual chaos!\")\n",
    "                break\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Test the corrupted ritual\n",
    "print(\"üß™ Testing the corrupted forbidden ritual...\")\n",
    "corrupted_model = CandleBurningPredictor(input_features=1)\n",
    "corrupted_model = corrupted_forbidden_ritual(corrupted_model, candle_weights, burning_times)\n",
    "\n",
    "print(\"\\nüîç DEBUGGING CHALLENGE:\")\n",
    "print(\"Can you identify the critical error that makes this ritual dangerous?\")\n",
    "print(\"\\nHINT: The gradient spirits are not being properly dismissed between cycles!\")\n",
    "print(\"\\nMASTER'S WISDOM: 'The undisciplined mind accumulates old thoughts,'\")\n",
    "print(\"                 'just as the untrained gradient accumulates old directions.'\")\n",
    "print(\"\\nüí° SOLUTION: What single line of code would fix this corruption?\")\n",
    "print(\"\\nüéØ CHALLENGE: Fix the corrupted ritual and train successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ CONGRATULATIONS: MASTER OF THE FORBIDDEN KNOWLEDGE\n",
    "\n",
    "Master Pai-Torch bows deeply, a rare smile crossing their ancient features.\n",
    "\n",
    "\"Grasshopper, you have successfully mastered the forbidden knowledge of gradient descent! You have learned to:\n",
    "\n",
    "‚ú® **Tame the gradient spirits** through proper zero_grad() ritual  \n",
    "‚ö° **Predict candle burning times** with mystical accuracy  \n",
    "üßπ **Clean corrupted data** despite He-Ao-World's accidents  \n",
    "üåä **Harness momentum and scheduling** with Master Ao-Tougrad's wisdom  \n",
    "üèÆ **Process batches efficiently** using the ancient DataLoader arts  \n",
    "üî• **Debug dangerous training** when the spirits go wild  \n",
    "\n",
    "You are now ready to advance to **Dan 2: Temple Guardian**, where you will learn to protect your models from the demons of overfitting and the chaos of noisy data.\n",
    "\n",
    "But remember, young Temple Sweeper - this forbidden knowledge comes with great responsibility. Use it wisely, always respect the gradient spirits, and never forget to zero_grad().\n",
    "\n",
    "**Master Pai-Torch's Final Wisdom:**  \n",
    "*\"The path of the neural warrior begins with a single tensor, but leads to infinite possibilities. You have taken your first step into a larger world of deep learning mysteries.\"*\n",
    "\n",
    "**Master Ao-Tougrad's Silent Nod:**  \n",
    "*\"The gradient spirits have accepted you as their student. They will guide your learning in the trials to come.\"*\n",
    "\n",
    "üèØ **Welcome to the Temple of Neural Networks, Dan 1 Graduate!** üèØ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}