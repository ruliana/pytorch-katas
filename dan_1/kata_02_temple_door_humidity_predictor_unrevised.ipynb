{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ruliana/pytorch-katas/blob/main/dan_1/kata_02_temple_door_humidity_predictor_unrevised.ipynb)\n",
    "\n",
    "## 🏮 The Ancient Scroll Unfurls 🏮\n",
    "\n",
    "**COOK OH-PAI-TIMIZER'S DOOR WISDOM: THE SIGMOID GATE MYSTERY**\n",
    "\n",
    "Dan Level: 1 (Temple Sweeper) | Time: 45 minutes | Sacred Arts: Binary Classification, Sigmoid Activation, Threshold Decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📜 THE CHALLENGE\n",
    "\n",
    "Cook Oh-Pai-Timizer bustles through the temple corridors, balancing steaming bowls of sacred soup and muttering about the ancient wooden doors. \"These old doors,\" Cook says, wiping sweat from their brow, \"they have minds of their own! When the humidity rises, some stick like they're guarded by stubborn spirits, while others swing freely. Yesterday I nearly spilled an entire pot of precious lotus root broth trying to push through the meditation hall door!\"\n",
    "\n",
    "The wise cook has been observing patterns for months, noting how the temple's humidity affects each door's behavior. Now Cook seeks to master the art of prediction—to know which doors will stick before approaching them with precious cargo. \"If I can learn this pattern,\" Cook explains, \"I can plan my routes and avoid the sticky doors entirely. But I need more than just intuition—I need the mathematical wisdom of the sigmoid function to transform humidity measurements into clear yes-or-no decisions!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 THE SACRED OBJECTIVES\n",
    "\n",
    "By the end of this kata, you will have mastered:\n",
    "\n",
    "- [ ] **Binary Classification Fundamentals**: Learn to predict yes/no outcomes using neural networks\n",
    "- [ ] **Sigmoid Activation Mastery**: Transform continuous values into probabilities between 0 and 1\n",
    "- [ ] **Single-Variable Classification**: Build intuition with one input feature before tackling complex problems\n",
    "- [ ] **Threshold Decision Making**: Convert probabilities into actionable binary decisions\n",
    "- [ ] **Binary Cross-Entropy Loss**: Understand the mathematics of classification error measurement\n",
    "- [ ] **Probability Interpretation**: Learn to read and trust your model's confidence levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 FIRST CELL - ALL IMPORTS AND CONFIGURATION\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "# Set reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Global configuration constants\n",
    "DEFAULT_CHAOS_LEVEL = 0.1\n",
    "SACRED_SEED = 42\n",
    "HUMIDITY_THRESHOLD = 60.0  # Cook's observed critical humidity level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🍜 THE SACRED DATA GENERATION SCROLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_door_humidity_data(n_observations: int = 200, chaos_level: float = 0.1, \n",
    "                               sacred_seed: int = 42) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Generate observations of temple door behavior based on humidity levels.\n",
    "    \n",
    "    Cook Oh-Pai-Timizer's wisdom: Doors tend to stick when humidity > 60%\n",
    "    But ancient wood has its own mysterious patterns!\n",
    "    \n",
    "    Args:\n",
    "        n_observations: Number of door-testing incidents to simulate\n",
    "        chaos_level: Amount of wooden unpredictability (0.0 = perfectly predictable doors, 1.0 = chaos)\n",
    "        sacred_seed: Ensures consistent randomness for reproducible soup deliveries\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (humidity_levels, door_sticks) as sacred tensors\n",
    "        door_sticks: 1 = door sticks (avoid!), 0 = door opens smoothly\n",
    "    \"\"\"\n",
    "    torch.manual_seed(sacred_seed)\n",
    "    \n",
    "    # Temple humidity ranges from 20% (dry winter) to 90% (monsoon season)\n",
    "    humidity_levels = torch.rand(n_observations, 1) * 70 + 20\n",
    "    \n",
    "    # Cook's observed pattern: doors stick more often when humidity > 60%\n",
    "    # Create base probability using a smooth sigmoid-like pattern\n",
    "    stick_probability = torch.sigmoid((humidity_levels.squeeze() - HUMIDITY_THRESHOLD) / 5.0)\n",
    "    \n",
    "    # Add wooden chaos - sometimes doors surprise you!\n",
    "    chaos = torch.randn(n_observations) * chaos_level * 0.3\n",
    "    stick_probability = torch.clamp(stick_probability + chaos, 0.0, 1.0)\n",
    "    \n",
    "    # Convert probabilities to actual door behavior (0 or 1)\n",
    "    door_sticks = torch.bernoulli(stick_probability).unsqueeze(1)\n",
    "    \n",
    "    return humidity_levels, door_sticks\n",
    "\n",
    "def visualize_door_wisdom(humidity: torch.Tensor, door_sticks: torch.Tensor, \n",
    "                         predictions: torch.Tensor = None):\n",
    "    \"\"\"\n",
    "    Display the sacred patterns of door behavior vs humidity.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Create two subplots\n",
    "    plt.subplot(1, 2, 1)\n",
    "    \n",
    "    # Separate sticky and smooth doors for clear visualization\n",
    "    sticky_mask = door_sticks.squeeze() == 1\n",
    "    smooth_mask = door_sticks.squeeze() == 0\n",
    "    \n",
    "    plt.scatter(humidity[sticky_mask].numpy(), [1]*torch.sum(sticky_mask).item(), \n",
    "                alpha=0.6, color='red', s=50, label='Doors That Stick (Danger!)')\n",
    "    plt.scatter(humidity[smooth_mask].numpy(), [0]*torch.sum(smooth_mask).item(), \n",
    "                alpha=0.6, color='green', s=50, label='Doors That Open Smoothly')\n",
    "    \n",
    "    plt.axvline(x=HUMIDITY_THRESHOLD, color='orange', linestyle='--', alpha=0.7,\n",
    "                label=f'Cook\\'s Threshold ({HUMIDITY_THRESHOLD}% humidity)')\n",
    "    \n",
    "    plt.xlabel('Humidity Level (%)')\n",
    "    plt.ylabel('Door Behavior')\n",
    "    plt.title('Cook Oh-Pai-Timizer\\'s Door Observations')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.ylim(-0.2, 1.2)\n",
    "    plt.yticks([0, 1], ['Opens Smoothly', 'Sticks!'])\n",
    "    \n",
    "    # Second subplot for predictions if provided\n",
    "    if predictions is not None:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        \n",
    "        # Sort by humidity for smooth prediction curve\n",
    "        sorted_indices = torch.argsort(humidity.squeeze())\n",
    "        sorted_humidity = humidity[sorted_indices]\n",
    "        sorted_predictions = predictions[sorted_indices]\n",
    "        \n",
    "        plt.plot(sorted_humidity.numpy(), sorted_predictions.detach().numpy(), \n",
    "                'gold', linewidth=3, label='Your Sigmoid Predictions')\n",
    "        plt.scatter(humidity[sticky_mask].numpy(), [1]*torch.sum(sticky_mask).item(), \n",
    "                    alpha=0.4, color='red', s=30)\n",
    "        plt.scatter(humidity[smooth_mask].numpy(), [0]*torch.sum(smooth_mask).item(), \n",
    "                    alpha=0.4, color='green', s=30)\n",
    "        \n",
    "        plt.axhline(y=0.5, color='purple', linestyle=':', alpha=0.7,\n",
    "                    label='Decision Threshold (50%)')\n",
    "        plt.axvline(x=HUMIDITY_THRESHOLD, color='orange', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.xlabel('Humidity Level (%)')\n",
    "        plt.ylabel('Predicted Probability of Sticking')\n",
    "        plt.title('Your Mystical Door Predictions')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.ylim(-0.1, 1.1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚪 THE SIGMOID GATEWAY PREDICTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoorStickinessPredictor(nn.Module):\n",
    "    \"\"\"A mystical artifact for predicting when temple doors will misbehave.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_features: int = 1):\n",
    "        super(DoorStickinessPredictor, self).__init__()\n",
    "        # TODO: Create a Linear layer to transform humidity into raw predictions\n",
    "        # Hint: One input (humidity), one output (raw stickiness score)\n",
    "        self.linear = None\n",
    "        \n",
    "        # TODO: Add the sigmoid activation function\n",
    "        # Hint: torch.nn.Sigmoid() transforms any number into a probability (0 to 1)\n",
    "        self.sigmoid = None\n",
    "    \n",
    "    def forward(self, features: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Transform humidity measurements into door-sticking probabilities.\"\"\"\n",
    "        # TODO: Pass humidity through the linear layer first\n",
    "        raw_output = None\n",
    "        \n",
    "        # TODO: Apply sigmoid to convert raw output to probability (0-1 range)\n",
    "        # This is the magic that makes classification work!\n",
    "        probability = None\n",
    "        \n",
    "        return probability\n",
    "\n",
    "def train_door_predictor(model: nn.Module, features: torch.Tensor, target: torch.Tensor,\n",
    "                        epochs: int = 2000, learning_rate: float = 0.1) -> list:\n",
    "    \"\"\"\n",
    "    Train the door stickiness prediction model.\n",
    "    \n",
    "    Returns:\n",
    "        List of loss values during training\n",
    "    \"\"\"\n",
    "    # TODO: Choose the right loss function for binary classification\n",
    "    # Hint: Binary Cross Entropy Loss is the master's choice for yes/no problems\n",
    "    criterion = None\n",
    "    \n",
    "    # TODO: Choose your optimizer\n",
    "    # Hint: SGD with higher learning rate works well for simple problems\n",
    "    optimizer = None\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # TODO: CRITICAL - Clear gradients from previous iteration\n",
    "        # The spirits of old gradients must be banished!\n",
    "        \n",
    "        # TODO: Forward pass - get probability predictions\n",
    "        predictions = None\n",
    "        \n",
    "        # TODO: Calculate binary classification loss\n",
    "        loss = None\n",
    "        \n",
    "        # TODO: Backward pass - compute gradients\n",
    "        \n",
    "        # TODO: Update model parameters\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # Report progress to Cook Oh-Pai-Timizer\n",
    "        if (epoch + 1) % 200 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "            if loss.item() < 0.3:\n",
    "                print(\"🍜 Cook Oh-Pai-Timizer nods approvingly - the wisdom flows!\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "def make_door_decisions(model: nn.Module, humidity: torch.Tensor, threshold: float = 0.5) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert probability predictions into binary door decisions.\n",
    "    \n",
    "    Args:\n",
    "        model: Your trained predictor\n",
    "        humidity: Humidity measurements\n",
    "        threshold: Decision boundary (default 0.5 means 50% confidence)\n",
    "    \n",
    "    Returns:\n",
    "        Binary decisions: 1 = door will stick (avoid!), 0 = door opens smoothly\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        probabilities = model(humidity)\n",
    "        decisions = (probabilities > threshold).float()\n",
    "    return decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡ THE TRIALS OF MASTERY\n",
    "\n",
    "### Trial 1: Basic Sigmoid Mastery\n",
    "- [ ] Loss decreases smoothly (no oscillating spirits)\n",
    "- [ ] Final loss below 0.4 (Cook Oh-Pai-Timizer's approval threshold)\n",
    "- [ ] Model outputs probabilities between 0 and 1 (sigmoid magic working)\n",
    "- [ ] Predictions show clear S-curve pattern when plotted against humidity\n",
    "\n",
    "### Trial 2: Decision Accuracy Test\n",
    "- [ ] Achieve >75% accuracy on training data\n",
    "- [ ] Model correctly identifies most doors above 60% humidity as \"sticky\"\n",
    "- [ ] Model correctly identifies most doors below 60% humidity as \"smooth\"\n",
    "\n",
    "### Trial 3: Understanding Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_your_wisdom(model):\n",
    "    \"\"\"Cook Oh-Pai-Timizer's evaluation of your door prediction skills.\"\"\"\n",
    "    \n",
    "    # Test sigmoid activation is working\n",
    "    test_humidity = torch.tensor([[30.0], [60.0], [80.0]])  # Low, medium, high humidity\n",
    "    predictions = model(test_humidity)\n",
    "    \n",
    "    # All predictions should be probabilities (0 to 1)\n",
    "    assert torch.all(predictions >= 0) and torch.all(predictions <= 1), \\\n",
    "        \"Sigmoid not working - predictions outside 0-1 range!\"\n",
    "    \n",
    "    # Higher humidity should generally mean higher sticking probability\n",
    "    assert predictions[2] > predictions[0], \\\n",
    "        \"High humidity should be stickier than low humidity!\"\n",
    "    \n",
    "    # Check model learned reasonable threshold behavior\n",
    "    low_humidity_pred = model(torch.tensor([[40.0]])).item()\n",
    "    high_humidity_pred = model(torch.tensor([[75.0]])).item()\n",
    "    \n",
    "    assert low_humidity_pred < 0.5, f\"Low humidity prediction {low_humidity_pred:.3f} should be < 0.5\"\n",
    "    assert high_humidity_pred > 0.5, f\"High humidity prediction {high_humidity_pred:.3f} should be > 0.5\"\n",
    "    \n",
    "    print(\"🎉 Cook Oh-Pai-Timizer beams with pride!\")\n",
    "    print(\"   'You have mastered the sigmoid way - doors shall no longer surprise you!'\")\n",
    "    print(f\"   Low humidity (40%): {low_humidity_pred:.1%} chance of sticking\")\n",
    "    print(f\"   High humidity (75%): {high_humidity_pred:.1%} chance of sticking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌸 THE FOUR PATHS OF MASTERY: PROGRESSIVE EXTENSIONS\n",
    "\n",
    "### Extension 1: Master Pai-Torch's Confidence Intervals\n",
    "*\"The wise cook knows not just whether a door will stick, but how certain that knowledge is.\"*\n",
    "\n",
    "*Master Pai-Torch appears in a swirl of steam from the kitchen*\n",
    "\n",
    "*\"Grasshopper, I observe your binary wisdom grows strong. But true mastery lies not just in prediction, but in understanding the confidence of that prediction. When your model says '70% chance of sticking,' what does this truly mean for Cook's soup delivery route?\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NEW CONCEPTS:** Probability interpretation, confidence thresholds, decision risk analysis  \n",
    "**DIFFICULTY:** +15% (still Dan 1, but deeper understanding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_prediction_confidence(model, humidity, target, confidence_thresholds=[0.3, 0.5, 0.7, 0.9]):\n",
    "    \"\"\"\n",
    "    Analyze how confident predictions perform with different decision thresholds.\n",
    "    \n",
    "    Args:\n",
    "        confidence_thresholds: Different cutoff points for \"door will stick\" decisions\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of {threshold: (accuracy, precision, recall)}\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        probabilities = model(humidity)\n",
    "        \n",
    "        for threshold in confidence_thresholds:\n",
    "            # TODO: Convert probabilities to binary decisions using this threshold\n",
    "            decisions = None\n",
    "            \n",
    "            # TODO: Calculate accuracy (correct predictions / total predictions)\n",
    "            accuracy = None\n",
    "            \n",
    "            # TODO: Calculate precision (correct \"stick\" predictions / all \"stick\" predictions)\n",
    "            # When you predict \"door will stick,\" how often are you right?\n",
    "            precision = None\n",
    "            \n",
    "            # TODO: Calculate recall (correct \"stick\" predictions / all actual sticky doors)\n",
    "            # Of all doors that actually stick, how many did you catch?\n",
    "            recall = None\n",
    "            \n",
    "            results[threshold] = (accuracy, precision, recall)\n",
    "            \n",
    "    return results\n",
    "\n",
    "def visualize_confidence_wisdom(results):\n",
    "    \"\"\"Display how different confidence thresholds affect decision quality.\"\"\"\n",
    "    thresholds = list(results.keys())\n",
    "    accuracies = [results[t][0] for t in thresholds]\n",
    "    precisions = [results[t][1] for t in thresholds]\n",
    "    recalls = [results[t][2] for t in thresholds]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(thresholds, accuracies, 'o-', label='Accuracy', linewidth=2)\n",
    "    plt.plot(thresholds, precisions, 's-', label='Precision', linewidth=2)\n",
    "    plt.plot(thresholds, recalls, '^-', label='Recall', linewidth=2)\n",
    "    \n",
    "    plt.xlabel('Confidence Threshold')\n",
    "    plt.ylabel('Performance Score')\n",
    "    plt.title('Master Pai-Torch\\'s Confidence Analysis')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.show()\n",
    "\n",
    "# TRIAL: Find the optimal confidence threshold for Cook's soup delivery needs\n",
    "# SUCCESS: Understand the tradeoff between catching sticky doors vs. false alarms\n",
    "# MASTERY: Explain why Cook might prefer high recall over high precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension 2: He-Ao-World's Measurement Mishaps\n",
    "*\"Oh dear! My old hands mixed up some of the humidity readings...\"*\n",
    "\n",
    "*He-Ao-World shuffles over, looking apologetic as always*\n",
    "\n",
    "*\"I was maintaining the humidity sensors yesterday and, well... some of them might be reading in different units now. Some show relative humidity, others show absolute humidity, and a few might be completely miscalibrated. The data looks quite scattered now. Cook Oh-Pai-Timizer is most understanding, but we need to make sense of this chaos before the evening soup service!\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NEW CONCEPTS:** Data preprocessing, outlier detection, robust training  \n",
    "**DIFFICULTY:** +25% (still Dan 1, but messier real-world data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_messy_humidity_data(n_observations: int = 200, chaos_level: float = 0.2):\n",
    "    \"\"\"\n",
    "    Generate humidity data with He-Ao-World's \"accidental\" measurement inconsistencies.\n",
    "    \n",
    "    Returns:\n",
    "        Messy humidity data with different scales and outliers\n",
    "    \"\"\"\n",
    "    # Start with clean data\n",
    "    clean_humidity, door_sticks = generate_door_humidity_data(n_observations, chaos_level)\n",
    "    \n",
    "    # He-Ao-World's \"accidents\"\n",
    "    messy_humidity = clean_humidity.clone()\n",
    "    \n",
    "    # 20% of readings are in absolute humidity (different scale)\n",
    "    absolute_mask = torch.rand(n_observations) < 0.2\n",
    "    messy_humidity[absolute_mask] = messy_humidity[absolute_mask] * 2.5 + 30\n",
    "    \n",
    "    # 10% of readings are completely wrong (sensor failures)\n",
    "    broken_mask = torch.rand(n_observations) < 0.1\n",
    "    messy_humidity[broken_mask] = torch.rand(torch.sum(broken_mask).item(), 1) * 200 + 100\n",
    "    \n",
    "    # 5% of readings are negative (impossible but happens with broken sensors)\n",
    "    negative_mask = torch.rand(n_observations) < 0.05\n",
    "    messy_humidity[negative_mask] = -torch.rand(torch.sum(negative_mask).item(), 1) * 50\n",
    "    \n",
    "    return messy_humidity, door_sticks\n",
    "\n",
    "def clean_humidity_data(messy_humidity: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Clean He-Ao-World's messy humidity measurements.\n",
    "    \n",
    "    Returns:\n",
    "        Cleaned humidity data ready for training\n",
    "    \"\"\"\n",
    "    cleaned = messy_humidity.clone()\n",
    "    \n",
    "    # TODO: Remove impossible values (negative humidity, >100% relative humidity)\n",
    "    # Hint: Use torch.clamp to constrain values to reasonable range\n",
    "    \n",
    "    # TODO: Detect and handle outliers (values way outside normal range)\n",
    "    # Hint: Calculate mean and standard deviation, cap extreme values\n",
    "    \n",
    "    # TODO: Normalize the data to 0-100 range for consistency\n",
    "    # Hint: min-max normalization works well here\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "def visualize_data_cleaning(messy_data, clean_data, target):\n",
    "    \"\"\"Show the before and after of He-Ao-World's data cleaning.\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.scatter(messy_data.numpy(), target.numpy(), alpha=0.6, color='red')\n",
    "    plt.xlabel('Messy Humidity Readings')\n",
    "    plt.ylabel('Door Sticks (1=Yes, 0=No)')\n",
    "    plt.title('He-Ao-World\\'s \"Oops!\"')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.scatter(clean_data.numpy(), target.numpy(), alpha=0.6, color='blue')\n",
    "    plt.xlabel('Cleaned Humidity Readings')\n",
    "    plt.ylabel('Door Sticks (1=Yes, 0=No)')\n",
    "    plt.title('After Cleaning')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.hist(messy_data.numpy(), bins=30, alpha=0.5, color='red', label='Messy')\n",
    "    plt.hist(clean_data.numpy(), bins=30, alpha=0.5, color='blue', label='Clean')\n",
    "    plt.xlabel('Humidity Values')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Data Distribution')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# TRIAL: Train your model on both messy and clean data\n",
    "# SUCCESS: Clean data achieves significantly better performance\n",
    "# MASTERY: Understand why data quality matters more than model complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension 3: Cook Oh-Pai-Timizer's Route Optimization\n",
    "*\"A wise cook plans the path, not just the destination!\"*\n",
    "\n",
    "*Cook Oh-Pai-Timizer sets down a wooden spoon and unfolds an ancient map of the temple*\n",
    "\n",
    "*\"Now that you can predict individual doors, young grasshopper, let us think bigger! I must deliver soup to five different halls, and each has multiple entrances. Your door wisdom must guide me to find the path of least resistance - the route where I'm most likely to encounter only smooth-opening doors. This is optimization, my eager student!\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NEW CONCEPTS:** Multi-door prediction, path optimization, practical decision making  \n",
    "**DIFFICULTY:** +35% (still Dan 1, but applying knowledge to complex scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_temple_route_data(n_routes: int = 50):\n",
    "    \"\"\"\n",
    "    Generate data for multiple temple routes, each with several doors.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with route information and door predictions needed\n",
    "    \"\"\"\n",
    "    routes = {}\n",
    "    \n",
    "    for route_id in range(n_routes):\n",
    "        # Each route has 3-7 doors to pass through\n",
    "        n_doors = torch.randint(3, 8, (1,)).item()\n",
    "        \n",
    "        # Generate humidity for each door along this route\n",
    "        door_humidity = torch.rand(n_doors, 1) * 70 + 20\n",
    "        \n",
    "        routes[f'route_{route_id}'] = {\n",
    "            'door_humidity': door_humidity,\n",
    "            'n_doors': n_doors\n",
    "        }\n",
    "    \n",
    "    return routes\n",
    "\n",
    "def predict_route_success(model, route_humidity: torch.Tensor, success_threshold: float = 0.8):\n",
    "    \"\"\"\n",
    "    Predict the probability that Cook can complete a route without encountering sticky doors.\n",
    "    \n",
    "    Args:\n",
    "        route_humidity: Humidity levels for all doors on this route\n",
    "        success_threshold: What probability of \"smooth\" door is considered safe\n",
    "    \n",
    "    Returns:\n",
    "        Overall route success probability\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # TODO: Get sticking probabilities for each door\n",
    "        stick_probabilities = None\n",
    "        \n",
    "        # TODO: Convert to \"smooth opening\" probabilities\n",
    "        smooth_probabilities = None\n",
    "        \n",
    "        # TODO: Calculate overall route success probability\n",
    "        # Hint: All doors must open smoothly, so multiply probabilities\n",
    "        route_success_prob = None\n",
    "        \n",
    "    return route_success_prob\n",
    "\n",
    "def find_best_routes(model, routes_data, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Find the safest routes for Cook's soup delivery mission.\n",
    "    \n",
    "    Returns:\n",
    "        List of (route_id, success_probability) sorted by safety\n",
    "    \"\"\"\n",
    "    route_scores = []\n",
    "    \n",
    "    for route_id, route_info in routes_data.items():\n",
    "        # TODO: Calculate success probability for this route\n",
    "        success_prob = None\n",
    "        \n",
    "        route_scores.append((route_id, success_prob.item()))\n",
    "    \n",
    "    # Sort by success probability (highest first)\n",
    "    route_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return route_scores[:top_k]\n",
    "\n",
    "def visualize_route_analysis(model, routes_data, best_routes):\n",
    "    \"\"\"Display Cook's route optimization wisdom.\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Show top 3 routes\n",
    "    for i, (route_id, success_prob) in enumerate(best_routes[:3]):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        \n",
    "        route_info = routes_data[route_id]\n",
    "        humidity = route_info['door_humidity']\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            stick_probs = model(humidity)\n",
    "        \n",
    "        door_numbers = range(1, len(humidity) + 1)\n",
    "        plt.bar(door_numbers, stick_probs.numpy().flatten(), \n",
    "                color=['green' if p < 0.5 else 'red' for p in stick_probs.flatten()])\n",
    "        \n",
    "        plt.title(f'Route {i+1}\\nSuccess: {success_prob:.1%}')\n",
    "        plt.xlabel('Door Number')\n",
    "        plt.ylabel('Stick Probability')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.axhline(y=0.5, color='purple', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Overall route success distribution\n",
    "    plt.subplot(2, 1, 2)\n",
    "    all_success_probs = [success_prob for _, success_prob in \n",
    "                        [(rid, predict_route_success(model, routes_data[rid]['door_humidity']).item()) \n",
    "                         for rid in routes_data.keys()]]\n",
    "    \n",
    "    plt.hist(all_success_probs, bins=20, alpha=0.7, color='blue')\n",
    "    plt.axvline(x=np.mean(all_success_probs), color='red', linestyle='--', \n",
    "                label=f'Average: {np.mean(all_success_probs):.1%}')\n",
    "    plt.xlabel('Route Success Probability')\n",
    "    plt.ylabel('Number of Routes')\n",
    "    plt.title('Distribution of All Route Success Rates')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# TRIAL: Find the safest routes for Cook's soup delivery\n",
    "# SUCCESS: Identify routes with >80% success probability\n",
    "# MASTERY: Understand how individual predictions combine into system-level decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension 4: Suki's Seasonal Wisdom\n",
    "*\"Meow meow purr... meow purr purr meow.\" (Translation: \"Young human, the doors behave differently in different seasons.\")*\n",
    "\n",
    "*Suki sits regally beside a weather scroll, tail twitching with knowing wisdom*\n",
    "\n",
    "*Master Pai-Torch translates: \"The sacred cat observes what your model cannot see - that humidity alone tells only part of the story. Winter humidity affects doors differently than summer humidity. The wood remembers the season, even if your measurements do not. Can your wisdom adapt to these deeper patterns?\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NEW CONCEPTS:** Feature engineering, seasonal patterns, model limitations  \n",
    "**DIFFICULTY:** +45% (still Dan 1, but thinking beyond single variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seasonal_door_data(n_observations: int = 400):\n",
    "    \"\"\"\n",
    "    Generate door data that includes seasonal effects.\n",
    "    \n",
    "    Returns:\n",
    "        Enhanced data with seasonal patterns that pure humidity can't capture\n",
    "    \"\"\"\n",
    "    # Generate humidity as before\n",
    "    humidity = torch.rand(n_observations, 1) * 70 + 20\n",
    "    \n",
    "    # Add seasonal information (0=winter, 1=spring, 2=summer, 3=autumn)\n",
    "    seasons = torch.randint(0, 4, (n_observations,))\n",
    "    \n",
    "    # Seasonal effects on door behavior\n",
    "    seasonal_adjustments = torch.zeros(n_observations)\n",
    "    seasonal_adjustments[seasons == 0] = -10  # Winter: doors shrink, stick less\n",
    "    seasonal_adjustments[seasons == 1] = +5   # Spring: moderate swelling\n",
    "    seasonal_adjustments[seasons == 2] = +15  # Summer: maximum expansion\n",
    "    seasonal_adjustments[seasons == 3] = +0   # Autumn: neutral\n",
    "    \n",
    "    # Effective humidity includes seasonal wood behavior\n",
    "    effective_humidity = humidity.squeeze() + seasonal_adjustments\n",
    "    effective_humidity = torch.clamp(effective_humidity, 0, 100)\n",
    "    \n",
    "    # Generate door behavior based on effective humidity\n",
    "    stick_probability = torch.sigmoid((effective_humidity - 60) / 5.0)\n",
    "    door_sticks = torch.bernoulli(stick_probability).unsqueeze(1)\n",
    "    \n",
    "    return humidity, door_sticks, seasons\n",
    "\n",
    "def compare_seasonal_vs_simple_models(humidity, door_sticks, seasons):\n",
    "    \"\"\"\n",
    "    Train two models: one with just humidity, one with seasonal awareness.\n",
    "    \n",
    "    Returns:\n",
    "        Comparison of model performances\n",
    "    \"\"\"\n",
    "    # Simple humidity-only model (what you've been building)\n",
    "    simple_model = DoorStickinessPredictor(input_features=1)\n",
    "    \n",
    "    # TODO: Create a seasonal-aware model\n",
    "    # Hint: You could create features like \"summer_humidity\" = humidity * is_summer\n",
    "    # Or create separate humidity thresholds for each season\n",
    "    \n",
    "    # TODO: Train both models and compare their performance\n",
    "    \n",
    "    # TODO: Calculate accuracy for each season separately\n",
    "    \n",
    "    return {}\n",
    "\n",
    "def analyze_model_limitations(simple_model, humidity, door_sticks, seasons):\n",
    "    \"\"\"\n",
    "    Understand where your humidity-only model fails.\n",
    "    \n",
    "    Returns:\n",
    "        Analysis of prediction errors by season\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        predictions = simple_model(humidity)\n",
    "        binary_predictions = (predictions > 0.5).float()\n",
    "        \n",
    "        # Calculate accuracy for each season\n",
    "        seasonal_accuracy = {}\n",
    "        for season in [0, 1, 2, 3]:\n",
    "            season_mask = seasons == season\n",
    "            if torch.sum(season_mask) > 0:\n",
    "                season_accuracy[season] = torch.mean(\n",
    "                    (binary_predictions[season_mask] == door_sticks[season_mask]).float()\n",
    "                ).item()\n",
    "        \n",
    "        return seasonal_accuracy\n",
    "\n",
    "def visualize_seasonal_patterns(humidity, door_sticks, seasons, model=None):\n",
    "    \"\"\"Show how door behavior varies by season.\"\"\"\n",
    "    season_names = ['Winter', 'Spring', 'Summer', 'Autumn']\n",
    "    colors = ['blue', 'green', 'red', 'orange']\n",
    "    \n",
    "    plt.figure(figsize=(16, 10))\n",
    "    \n",
    "    # Seasonal scatter plots\n",
    "    for i, season in enumerate([0, 1, 2, 3]):\n",
    "        plt.subplot(2, 4, i+1)\n",
    "        season_mask = seasons == season\n",
    "        \n",
    "        season_humidity = humidity[season_mask]\n",
    "        season_doors = door_sticks[season_mask]\n",
    "        \n",
    "        sticky_mask = season_doors.squeeze() == 1\n",
    "        smooth_mask = season_doors.squeeze() == 0\n",
    "        \n",
    "        plt.scatter(season_humidity[sticky_mask], [1]*torch.sum(sticky_mask).item(),\n",
    "                   alpha=0.6, color='red', s=30, label='Sticky')\n",
    "        plt.scatter(season_humidity[smooth_mask], [0]*torch.sum(smooth_mask).item(),\n",
    "                   alpha=0.6, color='green', s=30, label='Smooth')\n",
    "        \n",
    "        plt.title(f'{season_names[i]}')\n",
    "        plt.xlabel('Humidity (%)')\n",
    "        plt.ylabel('Door Behavior')\n",
    "        plt.ylim(-0.2, 1.2)\n",
    "        plt.yticks([0, 1], ['Smooth', 'Sticky'])\n",
    "        if i == 0:\n",
    "            plt.legend()\n",
    "    \n",
    "    # Model predictions by season (if provided)\n",
    "    if model is not None:\n",
    "        for i, season in enumerate([0, 1, 2, 3]):\n",
    "            plt.subplot(2, 4, i+5)\n",
    "            season_mask = seasons == season\n",
    "            \n",
    "            season_humidity = humidity[season_mask]\n",
    "            sorted_indices = torch.argsort(season_humidity.squeeze())\n",
    "            sorted_humidity = season_humidity[sorted_indices]\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                sorted_predictions = model(sorted_humidity)\n",
    "            \n",
    "            plt.plot(sorted_humidity.numpy(), sorted_predictions.numpy(), \n",
    "                    color=colors[i], linewidth=2)\n",
    "            plt.title(f'{season_names[i]} Predictions')\n",
    "            plt.xlabel('Humidity (%)')\n",
    "            plt.ylabel('Stick Probability')\n",
    "            plt.ylim(0, 1)\n",
    "            plt.axhline(y=0.5, color='purple', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# TRIAL: Discover the limitations of your humidity-only model\n",
    "# SUCCESS: Identify that some seasons are harder to predict than others\n",
    "# MASTERY: Understand that good models know their limitations\n",
    "# ENLIGHTENMENT: Realize that feature engineering can be more powerful than complex models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔥 CORRECTING YOUR FORM: A STANCE IMBALANCE\n",
    "\n",
    "*Cook Oh-Pai-Timizer pauses in their soup preparation, wooden spoon raised thoughtfully*\n",
    "\n",
    "*\"Ah, young grasshopper, I see you rush ahead like boiling water - eager but lacking patience! Your classification stance has become unsteady. See how your sigmoid predictions dance wildly, never settling into the smooth curve they should follow?\"*\n",
    "\n",
    "*A previous student left this flawed door prediction ritual. The training process has lost its balance - can you restore proper technique?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsteady_classification_training(model, features, target, epochs=2000):\n",
    "    \"\"\"This classification training has lost its balance - your form needs correction! 🥋\"\"\"\n",
    "    \n",
    "    # Using the wrong loss function for classification!\n",
    "    criterion = nn.MSELoss()  # This is for regression, not classification!\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        predictions = model(features)\n",
    "        loss = criterion(predictions, target)\n",
    "        \n",
    "        # Backward pass - but missing a critical step!\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if epoch % 200 == 0:\n",
    "            print(f'Epoch {epoch}: Loss = {loss.item():.4f}')\n",
    "    \n",
    "    return losses\n",
    "\n",
    "# DEBUGGING CHALLENGE: Can you spot the TWO critical errors in this training ritual?\n",
    "# \n",
    "# HINT 1: What loss function should you use for binary classification?\n",
    "# Cook's Wisdom: \"When predicting yes or no, don't measure with a ruler meant for 'how much'!\"\n",
    "# \n",
    "# HINT 2: What essential step is missing between loss.backward() and optimizer.step()?\n",
    "# Cook's Wisdom: \"Clean your bowls before cooking the next dish, or flavors will mix in chaos!\"\n",
    "#\n",
    "# MASTER'S DEEPER WISDOM: \"The eager student uses regression loss for classification problems,\n",
    "# thinking all prediction is the same. But classification seeks probability, while regression \n",
    "# seeks exact values. Choose your loss as carefully as you choose your cooking temperature!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎊 KATA COMPLETION CERTIFICATE\n",
    "\n",
    "*Upon successful completion of all trials, Cook Oh-Pai-Timizer approaches with a ceremonial ladle*\n",
    "\n",
    "**\"Congratulations, Grasshopper! You have mastered the Sigmoid Gateway Mystery!\"**\n",
    "\n",
    "### Your Earned Wisdom:\n",
    "- ✅ **Binary Classification Mastery**: You can now predict yes/no outcomes with neural networks\n",
    "- ✅ **Sigmoid Activation Understanding**: You transform raw outputs into meaningful probabilities\n",
    "- ✅ **Decision Threshold Wisdom**: You know how to convert predictions into actionable decisions\n",
    "- ✅ **Binary Cross-Entropy Fluency**: You measure classification errors with the proper loss function\n",
    "- ✅ **Confidence Interpretation**: You understand what probability predictions really mean\n",
    "- ✅ **Data Quality Awareness**: You can handle messy real-world data with preprocessing\n",
    "\n",
    "### Temple Standing:\n",
    "**Dan 1 (Temple Sweeper) - Sigmoid Gateway Specialist** 🚪✨\n",
    "\n",
    "*\"You have learned that the sigmoid function is like the temple gate - it stands between chaos and order, transforming any input into the sacred realm of probability. This wisdom will serve you well in your journey toward greater mastery!\"*\n",
    "\n",
    "**Ready for your next challenge? Consider advancing to Dan 2 or exploring more Dan 1 techniques!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}