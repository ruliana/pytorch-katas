{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ruliana/pytorch-katas/blob/main/dan_1/temple_candle_burning_predictor_unrevised.ipynb)\n",
    "\n",
    "üèÆ The Ancient Scroll Unfurls üèÆ\n",
    "\n",
    "THE TRIAL OF THE ETERNAL FLAME'S WISDOM\n",
    "Dan Level: 1 (Temple Sweeper) | Time: 60 minutes | Sacred Arts: Tensor Flows, Linear Wisdom, Training Rituals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìú THE MASTER'S CHALLENGE\n",
    "\n",
    "Young Grasshopper, your first sacred duty has arrived with the evening shadows.\n",
    "\n",
    "The temple's eternal flame candles burn throughout the night, illuminating the halls\n",
    "where ancient knowledge rests. Yet these sacred flames have been mysterious in their\n",
    "consumption - some burn bright and quick, others flicker slowly through the darkness.\n",
    "The monks have struggled to predict when each candle will extinguish, leading to\n",
    "halls plunged into darkness at crucial moments.\n",
    "\n",
    "*CLATTER!*\n",
    "\n",
    "\"Oh my! Terribly sorry!\" calls He-Ao-World from the candle storage room, where\n",
    "a cascade of measuring tools has just scattered across the floor. \"I was trying\n",
    "to organize the candle measurement scrolls and... well, some of the burn rate\n",
    "measurements got mixed up with the wick length records. These old eyes aren't\n",
    "what they used to be!\"\n",
    "\n",
    "\"The flame,\" whispers Master Pai-Torch from the meditation hall, unperturbed by\n",
    "the commotion, \"consumes wax as water flows downhill - predictable to those who\n",
    "understand the relationship between wick and time. The thicker the wick, the\n",
    "brighter the flame, the faster the consumption.\"\n",
    "\n",
    "Your sacred duty: Create a linear model that can predict how long a candle will\n",
    "burn based on its wick thickness.\n",
    "\n",
    "üéØ THE SACRED OBJECTIVES\n",
    "\n",
    "- [ ] Master the creation of data tensors from candle measurements\n",
    "- [ ] Forge your first Linear Wisdom artifact using torch.nn.Linear\n",
    "- [ ] Perform the Training Ritual: forward pass ‚Üí loss computation ‚Üí backpropagation ‚Üí parameter update\n",
    "- [ ] Observe the mystical loss decreasing over time (if it increases, you have angered the Gradient Spirits)\n",
    "- [ ] Predict when the temple flames will extinguish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üïØÔ∏è THE SACRED IMPORTS\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "\n",
    "# Ensure reproducible mystical results\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üïØÔ∏è THE SACRED DATA GENERATION SCROLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candle_burning_data(n_candles: int = 100, flame_chaos: float = 0.15,\n",
    "                               sacred_seed: int = 42) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Generate observations of sacred candle burning patterns.\n",
    "    \n",
    "    Ancient wisdom suggests: burn_time = -1.8 * wick_thickness + 12\n",
    "    (Thicker wicks burn brighter and faster, consuming wax more quickly)\n",
    "    \n",
    "    Args:\n",
    "        n_candles: Number of candle burning observations to simulate\n",
    "        flame_chaos: Amount of flame unpredictability (0.0 = perfectly predictable flame, 1.0 = pure chaos)\n",
    "        sacred_seed: Ensures consistent randomness for reproducible enlightenment\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (wick_thickness, burn_time_hours) as sacred tensors\n",
    "    \"\"\"\n",
    "    torch.manual_seed(sacred_seed)\n",
    "    \n",
    "    # Wick thickness ranges from 0.5mm to 4.0mm (temple candles come in various sizes)\n",
    "    wick_thickness = torch.rand(n_candles, 1) * 3.5 + 0.5\n",
    "    \n",
    "    # The sacred relationship known to ancient flame-keepers\n",
    "    base_burn_time = 12  # hours for a thin wick\n",
    "    burn_rate_per_thickness = -1.8  # thicker wicks burn faster\n",
    "    \n",
    "    burn_times = burn_rate_per_thickness * wick_thickness.squeeze() + base_burn_time\n",
    "    \n",
    "    # Add flame chaos (wind drafts, wax quality variations, etc.)\n",
    "    chaos = torch.randn(n_candles) * flame_chaos * burn_times.std()\n",
    "    burn_times = burn_times + chaos\n",
    "    \n",
    "    # Even mystical candles have physical limits\n",
    "    burn_times = torch.clamp(burn_times, 1.0, 15.0)\n",
    "    \n",
    "    return wick_thickness, burn_times.unsqueeze(1)\n",
    "\n",
    "def visualize_flame_wisdom(wick_thickness: torch.Tensor, burn_times: torch.Tensor,\n",
    "                         predictions: torch.Tensor = None):\n",
    "    \"\"\"Display the sacred patterns of candle burning.\"\"\"\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.scatter(wick_thickness.numpy(), burn_times.numpy(), alpha=0.6, color='orange',\n",
    "                label='Actual Candle Burn Times', s=60)\n",
    "    \n",
    "    if predictions is not None:\n",
    "        sorted_indices = torch.argsort(wick_thickness.squeeze())\n",
    "        sorted_thickness = wick_thickness[sorted_indices]\n",
    "        sorted_predictions = predictions[sorted_indices]\n",
    "        plt.plot(sorted_thickness.numpy(), sorted_predictions.detach().numpy(),\n",
    "                'gold', linewidth=3, label='Your Mystical Predictions')\n",
    "    \n",
    "    plt.xlabel('Wick Thickness (mm)')\n",
    "    plt.ylabel('Burn Time (hours)')\n",
    "    plt.title('üïØÔ∏è The Mysteries of Sacred Flame Duration üïØÔ∏è')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.ylim(0, 16)\n",
    "    plt.show()\n",
    "\n",
    "# Generate the sacred data\n",
    "wick_data, burn_time_data = generate_candle_burning_data()\n",
    "print(f\"Generated {len(wick_data)} sacred candle observations\")\n",
    "print(f\"Wick thickness range: {wick_data.min():.2f}mm to {wick_data.max():.2f}mm\")\n",
    "print(f\"Burn time range: {burn_time_data.min():.2f}h to {burn_time_data.max():.2f}h\")\n",
    "\n",
    "# Visualize the sacred patterns\n",
    "visualize_flame_wisdom(wick_data, burn_time_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî• FIRST MOVEMENTS: THE CANDLE FLAME PREDICTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CandleBurnPredictor(nn.Module):\n",
    "    \"\"\"A mystical artifact for understanding sacred flame duration patterns.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_features: int = 1):\n",
    "        super(CandleBurnPredictor, self).__init__()\n",
    "        # TODO: Create the Linear Wisdom layer\n",
    "        # Hint: torch.nn.Linear transforms input energy into output wisdom\n",
    "        # This should map from wick thickness to burn time\n",
    "        self.linear_wisdom = None\n",
    "    \n",
    "    def divine_burn_time(self, wick_thickness: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Channel your understanding through the mystical network.\"\"\"\n",
    "        # TODO: Pass the input through your Linear Wisdom\n",
    "        # Remember: even flames follow mathematical laws\n",
    "        return None\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"The sacred forward pass - this is called automatically by PyTorch.\"\"\"\n",
    "        return self.divine_burn_time(x)\n",
    "\n",
    "# Create your mystical predictor\n",
    "flame_predictor = CandleBurnPredictor()\n",
    "print(\"üî• Your Candle Burn Predictor has been forged!\")\n",
    "print(f\"Sacred parameters: {sum(p.numel() for p in flame_predictor.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚öîÔ∏è THE TRAINING RITUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_flame_predictor(model: nn.Module, X: torch.Tensor, y: torch.Tensor,\n",
    "                         epochs: int = 1000, learning_rate: float = 0.01) -> list:\n",
    "    \"\"\"\n",
    "    Train the candle burn prediction model.\n",
    "    \n",
    "    Returns:\n",
    "        List of loss values during training\n",
    "    \"\"\"\n",
    "    # TODO: Choose your loss calculation method\n",
    "    # Hint: Mean Squared Error is favored by the ancient flame-keepers\n",
    "    criterion = None\n",
    "    \n",
    "    # TODO: Choose your parameter updating method\n",
    "    # Hint: SGD is the traditional path, simple and effective\n",
    "    optimizer = None\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # TODO: CRITICAL - Clear the gradient spirits from previous cycle\n",
    "        # Hint: The spirits accumulate if not banished properly\n",
    "        \n",
    "        # TODO: Forward pass - get predictions\n",
    "        predictions = None\n",
    "        \n",
    "        # TODO: Compute the loss\n",
    "        loss = None\n",
    "        \n",
    "        # TODO: Backward pass - compute gradients\n",
    "        \n",
    "        # TODO: Update parameters\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # Report progress to Master Pai-Torch\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "            if loss.item() < 2.0:\n",
    "                print(\"üî• The Gradient Spirits dance in harmony with your progress!\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "# Begin the sacred training ritual\n",
    "print(\"üßò Beginning the Training Ritual...\")\n",
    "print(\"Master Pai-Torch watches from the shadows...\")\n",
    "\n",
    "# Training begins here - uncomment after implementing the TODOs\n",
    "# training_losses = train_flame_predictor(flame_predictor, wick_data, burn_time_data)\n",
    "# print(f\"\\n‚ú® Training complete! Final loss: {training_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìä VISUALIZATION OF THE SACRED TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment after training is complete\n",
    "# plt.figure(figsize=(12, 5))\n",
    "\n",
    "# # Plot training loss\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(training_losses, color='red', linewidth=2)\n",
    "# plt.title('üî• The Path of Gradient Descent')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.grid(True, alpha=0.3)\n",
    "\n",
    "# # Plot predictions vs actual\n",
    "# plt.subplot(1, 2, 2)\n",
    "# with torch.no_grad():\n",
    "#     predictions = flame_predictor(wick_data)\n",
    "#     visualize_flame_wisdom(wick_data, burn_time_data, predictions)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö° THE TRIALS OF MASTERY\n",
    "\n",
    "## Trial 1: Basic Mastery\n",
    "- [ ] Loss decreases consistently (no angry Gradient Spirits)\n",
    "- [ ] Final loss below 2.0 (The flame spirits approve of your predictions)\n",
    "- [ ] Model weight approximately -1.8 (¬±0.3), bias around 12 (¬±2)\n",
    "- [ ] Predictions form a clean line through the scattered data\n",
    "\n",
    "## Trial 2: Understanding Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_your_flame_wisdom(model):\n",
    "    \"\"\"Master Pai-Torch's evaluation of your understanding.\"\"\"\n",
    "    # Your model should produce correct shapes\n",
    "    test_thickness = torch.tensor([[1.0], [2.0], [3.0]])\n",
    "    predictions = model(test_thickness)\n",
    "    assert predictions.shape == (3, 1), \"The flame shapes must align with the sacred geometry!\"\n",
    "    \n",
    "    # Parameters should reflect the true flame nature\n",
    "    weight = model.linear_wisdom.weight.item()\n",
    "    bias = model.linear_wisdom.bias.item()\n",
    "    \n",
    "    print(f\"Learned weight: {weight:.3f} (should be around -1.8)\")\n",
    "    print(f\"Learned bias: {bias:.3f} (should be around 12)\")\n",
    "    \n",
    "    assert -2.5 <= weight <= -1.0, f\"Weight {weight:.2f} seems off - thicker wicks should burn faster!\"\n",
    "    assert 8 <= bias <= 16, f\"Bias {bias:.2f} - even thin wicks need base burn time!\"\n",
    "    \n",
    "    print(\"üéâ Master Pai-Torch nods with approval - your flame wisdom grows!\")\n",
    "\n",
    "# Test your wisdom after training\n",
    "# test_your_flame_wisdom(flame_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üå∏ THE FOUR PATHS OF MASTERY: PROGRESSIVE EXTENSIONS\n",
    "\n",
    "## Extension 1: Cook Oh-Pai-Timizer's Batch Lighting\n",
    "*\"A wise flame-keeper lights many candles at once, not one by one!\"*\n",
    "\n",
    "*Cook Oh-Pai-Timizer bustles over, carrying a tray of various candles*\n",
    "\n",
    "\"Ah, grasshopper! I see you've mastered predicting one candle at a time. But what happens\n",
    "when the evening ceremony requires lighting dozens of candles simultaneously? In my kitchen,\n",
    "efficiency comes from preparing multiple dishes at once - the same wisdom applies to flames!\"\n",
    "\n",
    "**NEW CONCEPTS**: Batch processing, tensor shapes, vectorized operations  \n",
    "**DIFFICULTY**: +15% (still Dan 1, but with batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ceremony_candle_data(n_ceremonies: int = 10, candles_per_ceremony: int = 20):\n",
    "    \"\"\"\n",
    "    Generate batched candle data for entire ceremonies.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (batch_thickness, batch_burn_times)\n",
    "        Shape: (n_ceremonies * candles_per_ceremony, 1) for both tensors\n",
    "    \"\"\"\n",
    "    # TODO: Create batched data that your model can process all at once\n",
    "    # Hint: Your existing model should work without changes!\n",
    "    pass\n",
    "\n",
    "# TRIAL: Feed batched data to your existing model\n",
    "# SUCCESS: Model processes multiple candles simultaneously, same accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension 2: He-Ao-World's Measurement Mix-up\n",
    "*\"These old eyes sometimes confuse the measurement scrolls...\"*\n",
    "\n",
    "*He-Ao-World shuffles over, looking apologetic*\n",
    "\n",
    "\"Oh dear! I was recording the wick measurements and... well, I might have mixed up\n",
    "some of the units. Some measurements are in millimeters, others in inches, and\n",
    "a few might be doubled by mistake. The data looks rather chaotic now!\"\n",
    "\n",
    "**NEW CONCEPTS**: Data normalization, feature scaling, handling inconsistent units  \n",
    "**DIFFICULTY**: +25% (still Dan 1, but messier data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_candle_data(thickness: torch.Tensor, burn_times: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Clean and normalize the candle data to handle measurement inconsistencies.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (normalized_thickness, normalized_burn_times)\n",
    "    \"\"\"\n",
    "    # TODO: Implement data normalization\n",
    "    # Hint: (data - mean) / std is a common normalization approach\n",
    "    # Remember: Store the normalization parameters for later use!\n",
    "    pass\n",
    "\n",
    "# TRIAL: Train your model on normalized data\n",
    "# SUCCESS: Model converges faster and more reliably"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension 3: Master Pai-Torch's Patience Teaching\n",
    "*\"The eager student trains too quickly and learns too little.\"*\n",
    "\n",
    "*Master Pai-Torch sits in contemplative silence*\n",
    "\n",
    "\"Young grasshopper, I observe your training ritual rushes like a mountain flame.\n",
    "But wisdom comes to those who vary their pace. Sometimes we must step boldly,\n",
    "sometimes cautiously, sometimes we must rest entirely to let the learning settle.\"\n",
    "\n",
    "**NEW CONCEPTS**: Learning rate scheduling, early stopping, training patience  \n",
    "**DIFFICULTY**: +35% (still Dan 1, but smarter training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patient_training_ritual(model, X, y, epochs=2000, patience=100):\n",
    "    \"\"\"\n",
    "    Train with patience and adaptive learning rate.\n",
    "    \n",
    "    Args:\n",
    "        patience: Stop training if loss doesn't improve for this many epochs\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (trained_model, loss_history, stopped_early)\n",
    "    \"\"\"\n",
    "    # TODO: Implement patient training with learning rate decay\n",
    "    # Hint: Start with lr=0.1, reduce by half every 500 epochs\n",
    "    # Hint: Keep track of best loss and stop if no improvement\n",
    "    pass\n",
    "\n",
    "# TRIAL: Compare patient training vs. rushed training\n",
    "# SUCCESS: Patient training achieves better final loss with fewer wasted epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension 4: The Temple's Candle Inventory Mystery\n",
    "*\"Understanding when flames extinguish is as important as predicting burn time.\"*\n",
    "\n",
    "*Master Pai-Torch gestures toward the temple's candle storage*\n",
    "\n",
    "\"The sacred flame keeper asks: 'Which candles will burn through the night ceremony?'\n",
    "Your linear wisdom is sound, but the true test is knowing when prediction becomes\n",
    "decision. At what burn time threshold do we consider a candle suitable for the\n",
    "8-hour night watch?\"\n",
    "\n",
    "**NEW CONCEPTS**: Threshold analysis, decision boundaries, model interpretation  \n",
    "**DIFFICULTY**: +45% (still Dan 1, but thinking beyond prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_ceremony_suitability(model, X, y, threshold_candidates=[6, 7, 8, 9, 10]):\n",
    "    \"\"\"\n",
    "    Analyze how well your model predicts which candles will last the night ceremony.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of {threshold: accuracy_score}\n",
    "    \"\"\"\n",
    "    # TODO: For each threshold, calculate:\n",
    "    # - How often model predicts \"candle will last\" (prediction > threshold)\n",
    "    # - How often this prediction is correct\n",
    "    # - Find the threshold that maximizes accuracy\n",
    "    pass\n",
    "\n",
    "def visualize_ceremony_decision_boundary(model, X, y, best_threshold):\n",
    "    \"\"\"\n",
    "    Show where your model draws the line between \"short burn\" and \"ceremony suitable\"\n",
    "    \"\"\"\n",
    "    # TODO: Create a visualization showing:\n",
    "    # - Original data points\n",
    "    # - Model predictions\n",
    "    # - Decision threshold line\n",
    "    # - Suitable/unsuitable regions\n",
    "    pass\n",
    "\n",
    "# TRIAL: Find the optimal threshold for night ceremony candles\n",
    "# SUCCESS: Achieve >80% accuracy in predicting ceremony suitability\n",
    "# MASTERY: Understand that good predictions don't always mean good decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî• CORRECTING YOUR FORM: A STANCE IMBALANCE\n",
    "\n",
    "Master Pai-Torch observes your training ritual with a careful eye. \"Your eager mind races ahead of your disciplined form, grasshopper. See how your gradient flow stance wavers?\"\n",
    "\n",
    "A previous disciple left this flawed training ritual. Your form has become unsteady - can you restore proper technique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsteady_flame_training(model, X, y, epochs=1000):\n",
    "    \"\"\"This training stance has lost its balance - your form needs correction! ü•ã\"\"\"\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        predictions = model(X)\n",
    "        loss = criterion(predictions, y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}: Loss = {loss.item():.4f}')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Master Pai-Torch's guidance: \"What sacred step is missing from this ritual?\"\n",
    "# Hint: The gradient spirits are not being properly dismissed between epochs...\n",
    "# Can you identify and fix the missing step?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéä COMPLETION CEREMONY\n",
    "\n",
    "When you have mastered all trials, you will have achieved:\n",
    "\n",
    "- **Tensor Mastery**: Creating and manipulating PyTorch tensors\n",
    "- **Linear Wisdom**: Understanding torch.nn.Linear transformations\n",
    "- **Training Discipline**: Proper gradient flow and parameter updates\n",
    "- **Sacred Debugging**: Identifying and fixing common training errors\n",
    "- **Flame Prediction**: Practical application of linear regression\n",
    "\n",
    "Master Pai-Torch nods approvingly: *\"The grasshopper has learned that even the simplest flame follows the laws of gradients. This wisdom will serve you well in greater trials to come.\"*\n",
    "\n",
    "üèÆ **Your Dan 1 Temple Sweeper certification is earned!** üèÆ\n",
    "\n",
    "The path to Dan 2 awaits..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}