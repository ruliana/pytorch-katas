{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ruliana/pytorch-katas/blob/main/dan_1/sacred_soup_proportions_unrevised.ipynb)\n",
    "\n",
    "## 🏮 The Ancient Scroll Unfurls 🏮\n",
    "\n",
    "**THE MYSTERY OF THE SACRED SOUP PROPORTIONS**\n",
    "\n",
    "Dan Level: 1 (Temple Sweeper) | Time: 60 minutes | Sacred Arts: Tensor Flows, Linear Wisdom, Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📜 THE MASTER'S CHALLENGE\n",
    "\n",
    "Young Grasshopper, a crisis has befallen our sacred temple kitchen!\n",
    "\n",
    "Cook Oh-Pai-Timizer bustles frantically around the kitchen, wooden spoon in hand, steam rising from numerous pots. \"Oh, Grasshopper! Terrible news! The ancient weighing scales—the ones passed down through generations of temple cooks—they have finally broken! *CLANG!* Just this morning, during the preparation of the sacred morning soup!\"\n",
    "\n",
    "Cook Oh-Pai-Timizer gestures helplessly at the broken bronze scales. \"For centuries, these scales have guided us in creating the perfect soup proportions. But now... how will we feed the temple masters without knowing the precise ingredient ratios?\"\n",
    "\n",
    "From the shadows of the kitchen doorway, Master Pai-Torch materializes, as always appearing when most needed. \"Young one,\" Master Pai-Torch speaks in cryptic whispers, \"the broken tool reveals the path to deeper wisdom. When the scales fail, the mind must learn to measure. The relationship between ingredients flows like water down a mountain—predictable to those who understand the current.\"\n",
    "\n",
    "Cook Oh-Pai-Timizer nods enthusiastically. \"Yes! I have been keeping detailed records for years! The amount of rice we use, and how much broth we need to add. Maybe... maybe you could help me discover the hidden recipe formula using these mystical 'neural networks' the masters speak of?\"\n",
    "\n",
    "Master Pai-Torch strokes an invisible beard. \"The gradient spirits whisper of ancient truths: *broth_amount = sacred_multiplier × rice_cups + base_liquid*. But the sacred multiplier and base liquid remain mysteries. Your linear wisdom must unveil them.\"\n",
    "\n",
    "## 🎯 THE SACRED OBJECTIVES\n",
    "\n",
    "Your sacred duty: Create a linear model that can predict the perfect amount of broth needed based on the cups of rice being prepared.\n",
    "\n",
    "- [ ] Master the creation of sacred data tensors\n",
    "- [ ] Forge your first Linear Wisdom artifact using torch.nn.Linear\n",
    "- [ ] Perform the Training Ritual: forward pass → loss computation → backpropagation → parameter update\n",
    "- [ ] Observe the mystical loss decreasing over time (if it increases, you have angered the Gradient Spirits)\n",
    "- [ ] Discover the hidden recipe formula that Cook Oh-Pai-Timizer has been following unconsciously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔮 SACRED IMPORTS - The Foundation of All Neural Arts\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "# Set the sacred seed for reproducible mystical results\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"🏮 The sacred libraries have been summoned!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🍲 THE SACRED DATA GENERATION SCROLL\n",
    "\n",
    "Cook Oh-Pai-Timizer's secret records reveal the ancient soup wisdom!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sacred_soup_data(n_batches: int = 120, cooking_chaos: float = 0.1, \n",
    "                             sacred_seed: int = 42) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Generate Cook Oh-Pai-Timizer's historical soup preparation data.\n",
    "    \n",
    "    The ancient wisdom suggests: broth_liters = 2.3 * rice_cups + 1.5\n",
    "    But cooking is an art, not an exact science, so there's always some variation!\n",
    "    \n",
    "    Args:\n",
    "        n_batches: Number of soup preparation records to simulate\n",
    "        cooking_chaos: Amount of natural cooking variation (0.0 = robot precision, 1.0 = pure chaos)\n",
    "        sacred_seed: Ensures consistent mystical randomness\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (rice_cups, broth_liters) as sacred tensors\n",
    "    \"\"\"\n",
    "    torch.manual_seed(sacred_seed)\n",
    "    \n",
    "    # Temple soup batches range from 1 to 15 cups of rice\n",
    "    rice_cups = torch.rand(n_batches, 1) * 14 + 1\n",
    "    \n",
    "    # Cook Oh-Pai-Timizer's unconscious formula (the hidden truth!)\n",
    "    base_broth = 1.5  # Always need some base liquid\n",
    "    rice_multiplier = 2.3  # Each cup of rice needs this much broth\n",
    "    \n",
    "    perfect_broth = rice_multiplier * rice_cups.squeeze() + base_broth\n",
    "    \n",
    "    # Add cooking chaos (even master cooks have slight variations)\n",
    "    chaos = torch.randn(n_batches) * cooking_chaos * perfect_broth.std()\n",
    "    actual_broth = perfect_broth + chaos\n",
    "    \n",
    "    # Even mystical soup has physical limits\n",
    "    actual_broth = torch.clamp(actual_broth, 0.5, 50)\n",
    "    \n",
    "    return rice_cups, actual_broth.unsqueeze(1)\n",
    "\n",
    "\n",
    "def visualize_soup_wisdom(rice: torch.Tensor, broth: torch.Tensor, \n",
    "                         predictions: torch.Tensor = None):\n",
    "    \"\"\"Display the sacred patterns of soup preparation.\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(rice.numpy(), broth.numpy(), alpha=0.6, color='brown', \n",
    "               s=60, label='Cook Oh-Pai-Timizer\\'s Historical Records')\n",
    "    \n",
    "    if predictions is not None:\n",
    "        # Sort for clean line plotting\n",
    "        sorted_indices = torch.argsort(rice.squeeze())\n",
    "        sorted_rice = rice[sorted_indices]\n",
    "        sorted_predictions = predictions[sorted_indices]\n",
    "        plt.plot(sorted_rice.numpy(), sorted_predictions.detach().numpy(), \n",
    "                'gold', linewidth=4, label='Your Mystical Predictions', alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('Cups of Sacred Rice', fontsize=12)\n",
    "    plt.ylabel('Liters of Mystical Broth', fontsize=12)\n",
    "    plt.title('🍲 The Sacred Soup Recipe Mysteries 🍲', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Generate and visualize the training data\n",
    "rice_cups, broth_liters = generate_sacred_soup_data()\n",
    "print(f\"📊 Generated {len(rice_cups)} sacred soup preparation records\")\n",
    "print(f\"Rice range: {rice_cups.min().item():.2f} to {rice_cups.max().item():.2f} cups\")\n",
    "print(f\"Broth range: {broth_liters.min().item():.2f} to {broth_liters.max().item():.2f} liters\")\n",
    "\n",
    "visualize_soup_wisdom(rice_cups, broth_liters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔥 FIRST MOVEMENTS - The Sacred Soup Predictor\n",
    "\n",
    "Cook Oh-Pai-Timizer watches eagerly as you begin crafting your linear wisdom artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SacredSoupPredictor(nn.Module):\n",
    "    \"\"\"A mystical artifact for understanding soup proportion wisdom.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_features: int = 1):\n",
    "        super(SacredSoupPredictor, self).__init__()\n",
    "        # TODO: Create the Linear Wisdom layer\n",
    "        # Hint: torch.nn.Linear transforms rice amount into broth prediction\n",
    "        # input_features=1 (rice cups), output_features=1 (broth liters)\n",
    "        self.linear_wisdom = None\n",
    "        \n",
    "    def divine_broth_amount(self, rice_cups: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Channel your understanding through the mystical network.\"\"\"\n",
    "        # TODO: Pass the rice cups through your Linear Wisdom\n",
    "        # Remember: even soup follows mathematical laws\n",
    "        return None\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"The sacred forward pass ritual.\"\"\"\n",
    "        return self.divine_broth_amount(x)\n",
    "\n",
    "\n",
    "def train_soup_oracle(model: nn.Module, X: torch.Tensor, y: torch.Tensor, \n",
    "                     epochs: int = 1000, learning_rate: float = 0.01) -> list:\n",
    "    \"\"\"\n",
    "    Train the sacred soup prediction model.\n",
    "    \n",
    "    Args:\n",
    "        model: Your SacredSoupPredictor\n",
    "        X: Rice amounts (input)\n",
    "        y: Broth amounts (target)\n",
    "        epochs: Training iterations\n",
    "        learning_rate: Step size for gradient descent\n",
    "        \n",
    "    Returns:\n",
    "        List of loss values during training\n",
    "    \"\"\"\n",
    "    # TODO: Choose your loss calculation method\n",
    "    # Hint: Mean Squared Error is favored by the ancient soup masters\n",
    "    criterion = None\n",
    "    \n",
    "    # TODO: Choose your parameter updating method\n",
    "    # Hint: SGD is the traditional path, simple and effective\n",
    "    optimizer = None\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # TODO: CRITICAL - Clear the gradient spirits from previous cycle\n",
    "        # Hint: The spirits accumulate if not banished properly\n",
    "        # optimizer.????()\n",
    "        \n",
    "        # TODO: Forward pass - predict broth amounts\n",
    "        predictions = None\n",
    "        \n",
    "        # TODO: Compute the loss between predictions and actual broth amounts\n",
    "        loss = None\n",
    "        \n",
    "        # TODO: Backward pass - compute gradients\n",
    "        # loss.????????()\n",
    "        \n",
    "        # TODO: Update parameters using computed gradients\n",
    "        # optimizer.????()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # Report progress to Cook Oh-Pai-Timizer\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "            if loss.item() < 0.5:\n",
    "                print(\"🍲 Cook Oh-Pai-Timizer claps with joy - the recipe is becoming clear!\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "\n",
    "# Create your sacred soup predictor\n",
    "# TODO: Instantiate your model\n",
    "soup_oracle = None\n",
    "\n",
    "print(\"🏮 Your Sacred Soup Predictor has been forged!\")\n",
    "print(f\"Model architecture: {soup_oracle}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌊 THE TRAINING RITUAL\n",
    "\n",
    "Master Pai-Torch observes silently as you begin the sacred training ceremony."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train your model using the sacred soup data\n",
    "# Hint: Use the train_soup_oracle function you completed above\n",
    "training_losses = None\n",
    "\n",
    "# Visualize the training progress\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot 1: Loss over time\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(training_losses, 'purple', linewidth=2)\n",
    "plt.title('🔥 Sacred Training Progress')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (Soup Prediction Error)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Final predictions vs actual data\n",
    "plt.subplot(1, 2, 2)\n",
    "with torch.no_grad():\n",
    "    final_predictions = soup_oracle(rice_cups)\n",
    "\n",
    "visualize_soup_wisdom(rice_cups, broth_liters, final_predictions)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"🎉 Training complete! Final loss: {training_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡ THE TRIALS OF MASTERY\n",
    "\n",
    "Cook Oh-Pai-Timizer eagerly awaits to see if you've discovered the hidden recipe formula!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_your_soup_wisdom(model):\n",
    "    \"\"\"Master Pai-Torch's evaluation of your understanding.\"\"\"\n",
    "    print(\"🧙 Master Pai-Torch emerges from the shadows for evaluation...\")\n",
    "    \n",
    "    # Test 1: Shape correctness\n",
    "    test_rice = torch.tensor([[3.0], [7.0], [12.0]])\n",
    "    predictions = model(test_rice)\n",
    "    assert predictions.shape == (3, 1), f\"The shapes must align! Got {predictions.shape}, expected (3, 1)\"\n",
    "    print(\"✅ Shape mastery confirmed\")\n",
    "    \n",
    "    # Test 2: Parameter interpretation\n",
    "    weight = model.linear_wisdom.weight.item()\n",
    "    bias = model.linear_wisdom.bias.item()\n",
    "    \n",
    "    print(f\"🔍 Discovered formula: broth = {weight:.3f} * rice + {bias:.3f}\")\n",
    "    \n",
    "    # The true formula was: broth = 2.3 * rice + 1.5\n",
    "    assert 2.0 <= weight <= 2.6, f\"Weight {weight:.3f} seems off - soup ratios should be around 2.3!\"\n",
    "    assert 1.0 <= bias <= 2.0, f\"Bias {bias:.3f} seems off - base broth should be around 1.5!\"\n",
    "    print(\"✅ Sacred formula parameters within acceptable range\")\n",
    "    \n",
    "    # Test 3: Practical predictions\n",
    "    print(\"\\n🍲 Testing practical soup predictions:\")\n",
    "    test_amounts = [2, 5, 10, 15]\n",
    "    with torch.no_grad():\n",
    "        for rice_amount in test_amounts:\n",
    "            predicted_broth = model(torch.tensor([[float(rice_amount)]]))\n",
    "            expected_broth = 2.3 * rice_amount + 1.5\n",
    "            error = abs(predicted_broth.item() - expected_broth)\n",
    "            print(f\"  {rice_amount} cups rice → {predicted_broth.item():.2f}L broth (expected ~{expected_broth:.2f}L, error: {error:.2f}L)\")\n",
    "    \n",
    "    print(\"\\n🎉 Cook Oh-Pai-Timizer beams with pride - you have mastered the sacred soup formula!\")\n",
    "    print(\"🧙 Master Pai-Torch nods approvingly: 'The gradient spirits smile upon your progress, young one.'\")\n",
    "    \n",
    "    return weight, bias\n",
    "\n",
    "# Test your trained model\n",
    "discovered_weight, discovered_bias = test_your_soup_wisdom(soup_oracle)\n",
    "\n",
    "print(f\"\\n📜 SACRED FORMULA REVEALED:\")\n",
    "print(f\"Broth Needed (liters) = {discovered_weight:.3f} × Rice Cups + {discovered_bias:.3f}\")\n",
    "print(f\"\\n🎯 SUCCESS CRITERIA:\")\n",
    "print(f\"- [ ] Loss decreases consistently: {'✅' if training_losses[0] > training_losses[-1] else '❌'}\")\n",
    "print(f\"- [ ] Final loss below 1.0: {'✅' if training_losses[-1] < 1.0 else '❌'}\")\n",
    "print(f\"- [ ] Weight approximately 2.3 (±0.3): {'✅' if abs(discovered_weight - 2.3) < 0.3 else '❌'}\")\n",
    "print(f\"- [ ] Bias approximately 1.5 (±0.5): {'✅' if abs(discovered_bias - 1.5) < 0.5 else '❌'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌸 THE FOUR PATHS OF MASTERY: PROGRESSIVE EXTENSIONS\n",
    "\n",
    "Cook Oh-Pai-Timizer and Master Pai-Torch have prepared additional challenges to deepen your understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension 1: Master Pai-Torch's Batch Wisdom\n",
    "*\"A true master feeds many mouths simultaneously, not one at a time.\"*\n",
    "\n",
    "Master Pai-Torch materializes beside you, stroking an invisible beard. \"Young one, your linear wisdom serves well for single soup batches. But what happens when the temple hosts a festival, and you must predict broth for multiple soup preparations simultaneously? Efficiency in the kitchen mirrors efficiency in computation.\"\n",
    "\n",
    "**NEW CONCEPTS**: Batch processing, tensor broadcasting, vectorized operations  \n",
    "**DIFFICULTY**: +15% (still Dan 1, but with batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_festival_soup_data(n_soup_varieties: int = 5, batches_per_variety: int = 30):\n",
    "    \"\"\"\n",
    "    Generate data for multiple soup varieties prepared simultaneously.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (batch_rice, batch_broth)\n",
    "        Shape: (n_soup_varieties * batches_per_variety, 1) for both tensors\n",
    "    \"\"\"\n",
    "    # TODO: Create batched data that your model can process all at once\n",
    "    # Hint: Your existing model should work without changes!\n",
    "    # Generate different soup varieties with slight variations in the base recipe\n",
    "    pass\n",
    "\n",
    "# TRIAL: Feed batched data to your existing model\n",
    "# SUCCESS: Model processes multiple soup varieties simultaneously, maintains accuracy\n",
    "print(\"🎊 Extension 1: Master your batch processing skills!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension 2: Cook Oh-Pai-Timizer's Ingredient Standardization\n",
    "*\"Different measuring cups, different results! A good cook adapts to any kitchen.\"*\n",
    "\n",
    "Cook Oh-Pai-Timizer rushes over, looking flustered. \"Oh dear! I just realized that over the years, I've been using different measuring cups! Some measurements are in traditional temple cups, others in modern metric cups, and some might be recorded in portions instead of absolute amounts. The recipe proportions are still correct, but the scales are all mixed up!\"\n",
    "\n",
    "**NEW CONCEPTS**: Data normalization, feature scaling, handling inconsistent units  \n",
    "**DIFFICULTY**: +25% (still Dan 1, but messier data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_recipe_measurements(rice: torch.Tensor, broth: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Standardize recipe measurements to handle inconsistent units.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (normalized_rice, normalized_broth, rice_stats, broth_stats)\n",
    "        The stats are needed to denormalize predictions later!\n",
    "    \"\"\"\n",
    "    # TODO: Implement data normalization\n",
    "    # Hint: (data - mean) / std is a common normalization approach\n",
    "    # Remember: Store the normalization parameters for later use!\n",
    "    pass\n",
    "\n",
    "def denormalize_predictions(normalized_preds: torch.Tensor, target_mean: float, target_std: float):\n",
    "    \"\"\"\n",
    "    Convert normalized predictions back to original units.\n",
    "    \"\"\"\n",
    "    # TODO: Reverse the normalization process\n",
    "    # Hint: If you normalized with (data - mean) / std, how do you reverse it?\n",
    "    pass\n",
    "\n",
    "# TRIAL: Train your model on normalized data\n",
    "# SUCCESS: Model converges faster and more reliably\n",
    "print(\"📏 Extension 2: Master data normalization for consistent results!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension 3: Master Pai-Torch's Patience Teaching\n",
    "*\"The eager student trains too quickly and learns too little.\"*\n",
    "\n",
    "Master Pai-Torch sits in contemplative silence, then speaks softly. \"Young grasshopper, I observe your training ritual rushes like a mountain stream. But wisdom comes to those who vary their pace. Sometimes we must step boldly, sometimes cautiously, and sometimes we must rest entirely. The path of adaptive learning reveals deeper truths.\"\n",
    "\n",
    "**NEW CONCEPTS**: Learning rate scheduling, early stopping, training patience  \n",
    "**DIFFICULTY**: +35% (still Dan 1, but smarter training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patient_training_ritual(model, X, y, epochs=2000, patience=100, initial_lr=0.1):\n",
    "    \"\"\"\n",
    "    Train with patience and adaptive learning rate.\n",
    "    \n",
    "    Args:\n",
    "        patience: Stop training if loss doesn't improve for this many epochs\n",
    "        initial_lr: Starting learning rate\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (trained_model, loss_history, stopped_early)\n",
    "    \"\"\"\n",
    "    # TODO: Implement patient training with learning rate decay\n",
    "    # Hint: Start with initial_lr, reduce by half every 500 epochs\n",
    "    # Hint: Keep track of best loss and stop if no improvement for 'patience' epochs\n",
    "    pass\n",
    "\n",
    "# TRIAL: Compare patient training vs. rushed training\n",
    "# SUCCESS: Patient training achieves better final loss with fewer wasted epochs\n",
    "print(\"🧘 Extension 3: Master the art of patient, adaptive training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension 4: Cook Oh-Pai-Timizer's Recipe Confidence\n",
    "*\"A wise cook knows not just the recipe, but how confident they are in each prediction.\"*\n",
    "\n",
    "Cook Oh-Pai-Timizer approaches with a thoughtful expression. \"You know, young one, after all these years of cooking, I've learned that some recipes are more reliable than others. When preparing soup for 2 people, I'm very confident in the proportions. But when cooking for 20 people? There's more uncertainty. Can your mystical model tell us not just how much broth to use, but how confident it is in each prediction?\"\n",
    "\n",
    "**NEW CONCEPTS**: Prediction uncertainty, confidence intervals, model interpretation  \n",
    "**DIFFICULTY**: +45% (still Dan 1, but thinking beyond point predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_prediction_confidence(model, X, y, n_bootstrap=100):\n",
    "    \"\"\"\n",
    "    Analyze how confident the model is in its predictions using bootstrap sampling.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with prediction statistics\n",
    "    \"\"\"\n",
    "    # TODO: Implement bootstrap sampling to estimate prediction uncertainty\n",
    "    # Hint: Train multiple models on different subsets of data\n",
    "    # Hint: Use the variance in predictions to estimate confidence\n",
    "    pass\n",
    "\n",
    "def visualize_prediction_confidence(model, X, y, confidence_data):\n",
    "    \"\"\"\n",
    "    Show predictions with confidence intervals.\n",
    "    \"\"\"\n",
    "    # TODO: Create a visualization showing:\n",
    "    # - Original data points\n",
    "    # - Model predictions\n",
    "    # - Confidence intervals (shaded regions)\n",
    "    # - Highlight regions where model is less confident\n",
    "    pass\n",
    "\n",
    "# TRIAL: Analyze your model's confidence across different rice amounts\n",
    "# SUCCESS: Identify regions where predictions are more/less reliable\n",
    "# MASTERY: Understand that good predictions should come with confidence estimates\n",
    "print(\"🎯 Extension 4: Master the art of prediction confidence!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔥 CORRECTING YOUR FORM: A STANCE IMBALANCE\n",
    "\n",
    "Master Pai-Torch observes your training ritual with a careful eye. \"Your eager mind races ahead of your disciplined form, grasshopper. See how your gradient flow stance wavers?\"\n",
    "\n",
    "A previous disciple left this flawed training ritual. Your form has become unsteady - can you restore proper technique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsteady_training_ritual(model, X, y, epochs=1000):\n",
    "    \"\"\"This training stance has lost its balance - your form needs correction! 🥋\"\"\"\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        predictions = model(X)\n",
    "        loss = criterion(predictions, y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}: Loss = {loss.item():.4f}')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# TODO: Identify and fix the critical error in this training function\n",
    "# Hint: Master Pai-Torch whispers: \"The gradient spirits accumulate when not properly banished...\"\n",
    "# Hint: What happens to gradients between epochs if you don't clear them?\n",
    "# Hint: Compare this function to your working train_soup_oracle function\n",
    "\n",
    "print(\"🔍 DEBUGGING CHALLENGE:\")\n",
    "print(\"Find the critical error that will cause gradient accumulation!\")\n",
    "print(\"Master Pai-Torch: 'Without proper gradient clearing, the spirits grow stronger and stronger...'\")\n",
    "\n",
    "# Uncomment to test the broken function (it will show exploding gradients!)\n",
    "# broken_model = SacredSoupPredictor()\n",
    "# unsteady_training_ritual(broken_model, rice_cups, broth_liters, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 GRADUATION: FROM TEMPLE SWEEPER TO SOUP MASTER\n",
    "\n",
    "Cook Oh-Pai-Timizer claps enthusiastically. \"Wonderful! You have mastered the sacred soup formula! No longer will broken scales prevent us from feeding the temple masters. You have learned the deeper truth - that relationships in data flow like water, predictable to those who understand the current.\"\n",
    "\n",
    "Master Pai-Torch nods with approval. \"Young one, you have taken your first steps on the path of neural wisdom. The linear transformation you have mastered today - `y = wx + b` - is the foundation of all neural architectures. Remember this sacred formula, for it appears in every layer of the deepest networks.\"\n",
    "\n",
    "**What you have accomplished:**\n",
    "- ✅ Mastered tensor creation and manipulation\n",
    "- ✅ Built your first neural network using `torch.nn.Linear`\n",
    "- ✅ Implemented the complete training loop: forward pass, loss calculation, backpropagation, parameter updates\n",
    "- ✅ Discovered the hidden relationship in data through gradient descent\n",
    "- ✅ Learned to interpret model parameters as real-world relationships\n",
    "\n",
    "**Next on your journey:**\n",
    "- Dan 2 will teach you about multiple layers and regularization\n",
    "- You'll learn to protect your models from overfitting\n",
    "- The temple guardians await with new challenges!\n",
    "\n",
    "🏮 *\"The path of a thousand neural networks begins with a single linear layer.\"* - Ancient Temple Wisdom"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}